{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8988e0",
   "metadata": {},
   "source": [
    "# Projeto de Sinais e Sistemas para Computa√ß√£o (SSC)\n",
    "\n",
    "## III - Algoritmo de Classifica√ß√£o\n",
    "\n",
    "Este notebook implementa o algoritmo de classifica√ß√£o:\n",
    "- **Random Forest**\n",
    "\n",
    "### Objetivos:\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae1d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necess√°rios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddd6500-902d-4460-a525-b7fa339b55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testes b√°sicos com base no que o gpt mandou\n",
    "# que seria criar um modelo para doen√ßa, pois as doen√ßas nao s√£o necessariamente classes excludentes\n",
    "# cada linha do features √© de uma deriva√ß√£o de um paciente x, ele sugeriu unir tudo em uma √∫nica linha de \n",
    "# um dataframe para treinar, basicamente criar uma matrix com todos os dados de uma deriva√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c946c0-fcbd-41ad-8452-b59729502311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3011c833-59a4-4f82-9a80-919652061455",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "data_path = \"../data/\"\n",
    "qtd_linhas_teste = 12 * 10000 # apenas 5 ecg diferentes, pois cada um ten 12 deriva√ß√µes\n",
    "df = pd.read_csv(data_path + \"features/features_dataset_completo_20250805_001604.csv\", nrows=qtd_linhas_teste)\n",
    "# ordenar o paciente pelo paciente e depois pela derivacao para ter certeza \n",
    "df = df.sort_values([\"ecg_id\", \"canal\"])\n",
    "colunas_descartar_df = [\"canal\", \"fs\", \"n_samples\", \"arquivo_origem\"]\n",
    "# tirando isso pois o canal se reprete(a ideia √© juntar todas as deriva√ß√µes em uma linha), o fs e o n_samples nao parecem adicionar nada de info\n",
    "df_f = df.drop(columns=colunas_descartar_df) # agrupa por paciente\n",
    "df_f = df_f.groupby(\"ecg_id\")\n",
    "pacientes = []\n",
    "for i, j in df_f: # i = nome do arquivo e j = conjunto de linhas(incluem o nome do arquivo ainda)\n",
    "    features = j.drop(columns=[\"ecg_id\"])\n",
    "    array_paciente = features.values.flatten()\n",
    "    # print(i, array_paciente, array_paciente.shape) # o shape √© (21 * 12), 21 colunas depois das eliminadas e 12 deriva√ßoes\n",
    "    pacientes.append((i, array_paciente))\n",
    "\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59fb3192-cd1e-4d26-bc27-8c0b6be4d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f82c7a1-f07d-4944-bc76-59aafa779efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pegando o Y database com base nas linhas testes\n",
    "pacientes_ids = []\n",
    "for i in pacientes:\n",
    "    pacientes_ids.append(i[0])\n",
    "# print(\"pacientes =\", pacientes_ids)\n",
    "# filtrar apenas os dados pegos\n",
    "df_dados = pd.read_csv(data_path + \"raw/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/ptbxl_database.csv\")\n",
    "# ele vai printar um index de coluna 1 a mais pois o df ele esta mostrando o idx da linhas e ele come√ßa com 0\n",
    "y = df_dados[df_dados[\"ecg_id\"].isin(pacientes_ids)][\"scp_codes\"].values\n",
    "y_evaled = [ast.literal_eval(item) for item in y]\n",
    "len(y_evaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e891b3-56fe-453b-a6f9-faefc4a9705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"NORM\", \"SR\", \"IMI\"] # so de teste, seria um modelo para cada um desses\n",
    "modelos = {}\n",
    "for i in classes:\n",
    "    # para cada classe ele pega a % de cada paciente, mas colocando de forma bin√°ria\n",
    "    # apenas 1 ou 0, melhorar isso, pois isso √© so o basico, o gpt ja alertou\n",
    "    '''\n",
    "    Isso cria um vetor bin√°rio (0 ou 1) para cada doen√ßa.\n",
    "    Se uma doen√ßa n√£o tiver nenhum caso positivo no conjunto de teste (ou no treino), o modelo nunca vai prever 1 e o c√°lculo de precision vai dar problema.\n",
    "    ele sugere isso\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    [f for _, f in pacientes],\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=Y  # garante propor√ß√£o de 0 e 1 nos dois conjuntos\n",
    "    )\n",
    "    '''\n",
    "    Y = np.array([1 if d.get(i, 0.0) > 0 else 0 for d in y_evaled])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        np.array([f for _, f in pacientes]), Y, test_size=0.2, random_state=42\n",
    "    ) # esse for basicamente pega apenas a matrx\n",
    "\n",
    "\n",
    "    '''\n",
    "    Doen√ßas raras s√£o um desafio.\n",
    "    Se voc√™ deixar o RandomForest \"solto\", ele pode prever sempre 0 e ainda assim ter uma alta acur√°cia.\n",
    "    O que ajuda:\n",
    "    clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    class_weight=\"balanced\",  # ajusta pesos automaticamente\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "    Par√¢metros mais importantes e seu efeito\n",
    "    Par√¢metro\tO que faz\tImpacto principal\n",
    "    n_estimators\tN√∫mero de √°rvores na floresta\tMais √°rvores = mais robusto, melhor precis√£o, mas mais tempo de treino e predi√ß√£o. Geralmente usar 100+ √© um bom ponto inicial.\n",
    "    max_depth\tProfundidade m√°xima de cada √°rvore\tLimita complexidade; controla overfitting. Muito fundo = √°rvores complexas, risco de overfitting; muito raso = underfitting.\n",
    "    min_samples_split\tM√≠nimo n√∫mero de amostras para dividir um n√≥\tControla o qu√£o ‚Äúexigente‚Äù √© para dividir n√≥s. Valores maiores reduzem overfitting.\n",
    "    min_samples_leaf\tM√≠nimo n√∫mero de amostras que um n√≥ folha deve ter\tEvita que a √°rvore crie folhas muito pequenas, ajudando a generalizar melhor.\n",
    "    max_features\tN√∫mero m√°ximo de features consideradas para divis√£o em cada n√≥\tControla a aleatoriedade. Valores menores aumentam vari√¢ncia entre √°rvores, ajudando a generalizar. Pode ser int, float ou ‚Äúauto‚Äù, ‚Äúsqrt‚Äù, ‚Äúlog2‚Äù.\n",
    "    bootstrap\tSe as amostras para construir cada √°rvore s√£o sorteadas com reposi√ß√£o\tTrue (default) = amostragem com reposi√ß√£o, aumenta diversidade entre √°rvores. False usa o dataset todo.\n",
    "    class_weight\tAjusta pesos das classes para balancear dados desbalanceados\tPode ser ‚Äúbalanced‚Äù, ‚Äúbalanced_subsample‚Äù ou um dict. Ajuda em problemas com classes muito desiguais.\n",
    "    random_state\tSemente do gerador de n√∫meros aleat√≥rios\tGarante resultados reproduz√≠veis. Usar valor fixo para repetir experimento.\n",
    "    n_jobs\tN√∫mero de CPUs usados para o treino\t-1 usa todos os n√∫cleos, acelera o treino.\n",
    "    max_samples\tPropor√ß√£o (ou n√∫mero) m√°ximo de amostras para treinar cada √°rvore (usado com bootstrap=True)\tControla tamanho da amostra bootstrap, pode reduzir overfitting.\n",
    "    \n",
    "    Como esses par√¢metros influenciam o modelo\n",
    "    Exemplo pr√°tico:\n",
    "    Aumentar n_estimators: melhora desempenho (menos vari√¢ncia), mas tempo aumenta linearmente.\n",
    "    \n",
    "    Ajustar max_depth: ajuda a controlar overfitting, especialmente em datasets pequenos ou ruidosos.\n",
    "    \n",
    "    min_samples_split e min_samples_leaf: aumentam a generaliza√ß√£o evitando √°rvores muito complexas.\n",
    "    \n",
    "    max_features menor: aumenta diversidade das √°rvores e pode melhorar generaliza√ß√£o.\n",
    "    \n",
    "    class_weight='balanced': essencial para dados com classes desbalanceadas, melhora performance em classes minorit√°rias.\n",
    "    \n",
    "    bootstrap=False: menos diversidade, pode levar a overfitting.\n",
    "    \n",
    "    random_state: s√≥ para garantir que resultados sejam iguais em execu√ß√µes diferentes.\n",
    "\n",
    "    \n",
    "    '''\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)    \n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    '''\n",
    "    No caso de classes desbalanceadas, accuracy engana.\n",
    "    Voc√™ j√° usa classification_report, mas pode tamb√©m monitorar:\n",
    "    \n",
    "    f1-score (mais robusto com desbalanceamento)\n",
    "    \n",
    "    roc_auc_score para bin√°rios\n",
    "    '''\n",
    "    print(f\"Acur√°cia de doenca({i}):\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    modelos[i] = clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8038d2-6e11-4cc5-b789-19bec2f209c4",
   "metadata": {},
   "source": [
    "Pergunta ao gpt:\n",
    "estou trabalhando com doen√ßas cardiacas e os % de classifica√ß√£o s√£o de classes que as vezes batem sendo iguais como posso relacionar, tipo, classe x √© subclasse de y ou vice versa, se ele identificar como x ou y ele identifica com a outra, e como posso passar um sinal por todos eles e conseguir todas essas classifica√ß√µes\n",
    "\n",
    "Resultado:\n",
    "1Ô∏è‚É£ Modelagem de classes hier√°rquicas ou relacionadas\n",
    "a) Definir uma hierarquia ou rede de rela√ß√µes\n",
    "Voc√™ pode criar uma estrutura que mostra rela√ß√µes entre as classes, por exemplo:\n",
    "\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "relacoes = {\n",
    "    \"doenca_y\": [\"doenca_x\", \"doenca_z\"],  # doenca_x e doenca_z s√£o subclasses de doenca_y\n",
    "    \"doenca_x\": [],\n",
    "    \"doenca_z\": [],\n",
    "    # outras classes ...\n",
    "}\n",
    "Ou se preferir, um grafo (usando networkx) para rela√ß√µes mais complexas.\n",
    "\n",
    "b) Regra de associa√ß√£o entre classes relacionadas\n",
    "Por exemplo, se o modelo identificar doenca_x com alta chance, voc√™ automaticamente considera doenca_y presente (porque √© pai/mais geral).\n",
    "\n",
    "2Ô∏è‚É£ Como passar um sinal e obter as classifica√ß√µes\n",
    "Supondo que voc√™ tenha modelos bin√°rios para v√°rias doen√ßas (como fez com Random Forest), voc√™ pode:\n",
    "\n",
    "Passar o vetor de features do paciente para todos os modelos.\n",
    "\n",
    "Obter as previs√µes (probabilidades ou classes).\n",
    "\n",
    "Aplicar a regra de hierarquia para \"expandir\" ou \"relacionar\" resultados.\n",
    "\n",
    "Exemplo simplificado:\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "# Modelos bin√°rios treinados para cada doen√ßa\n",
    "modelos = {\n",
    "    \"doenca_x\": modelo_x,\n",
    "    \"doenca_y\": modelo_y,\n",
    "    # ...\n",
    "}\n",
    "\n",
    "relacoes = {\n",
    "    \"doenca_y\": [\"doenca_x\"],  # doenca_x √© subclasse de doenca_y\n",
    "    \"doenca_x\": [],\n",
    "}\n",
    "\n",
    "def prever_com_relacoes(features, modelos, relacoes):\n",
    "    preds = {}\n",
    "    for doenca, modelo in modelos.items():\n",
    "        preds[doenca] = modelo.predict(features.reshape(1, -1))[0]\n",
    "\n",
    "    # Propagar presen√ßa para classes pais\n",
    "    for pai, filhos in relacoes.items():\n",
    "        if any(preds.get(filho, 0) == 1 for filho in filhos):\n",
    "            preds[pai] = 1  # se algum filho detectado, marca pai como presente\n",
    "\n",
    "    return preds\n",
    "\n",
    "# Usar:\n",
    "resultado = prever_com_relacoes(X_paciente, modelos, relacoes)\n",
    "print(resultado)\n",
    "3Ô∏è‚É£ Dicas extras\n",
    "Se suas classes s√£o mutuamente exclusivas em alguns n√≠veis, talvez valha a pena usar modelos hier√°rquicos (primeiro prever classe geral, depois subclassificar).\n",
    "\n",
    "Para sa√≠da probabil√≠stica, considere usar o m√©todo .predict_proba() para ajustar limiares e combinar evid√™ncias.\n",
    "\n",
    "Se quiser, pode usar t√©cnicas de classifica√ß√£o multi-label com depend√™ncias entre classes, como classifica√ß√£o hier√°rquica ‚Äî h√° bibliotecas espec√≠ficas para isso.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e98005",
   "metadata": {},
   "source": [
    "## 1. Carregamento e Prepara√ß√£o dos Dados\n",
    "\n",
    "Carregamos o dataset de caracter√≠sticas gerado no notebook anterior e preparamos os dados para classifica√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee50d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad67ea4e",
   "metadata": {},
   "source": [
    "## 2. Pr√©-processamento dos Dados\n",
    "\n",
    "Preparamos os dados para os algoritmos de classifica√ß√£o: divis√£o treino/teste, normaliza√ß√£o e codifica√ß√£o de labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33810479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e22d337",
   "metadata": {},
   "source": [
    "## 3. Implementa√ß√£o dos Algoritmos de Classifica√ß√£o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f827c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar modelos com hiperpar√¢metros otimizados\n",
    "modelos = {\n",
    "    'üå≤ Random Forest': {\n",
    "        'estimador': RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        'params_grid': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [5, 10, 15, None],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Dicion√°rio para armazenar resultados\n",
    "resultados = {\n",
    "    'modelo': [],\n",
    "    'acuracia_cv': [],\n",
    "    'std_cv': [],\n",
    "    'acuracia_teste': [],\n",
    "    'tempo_treino': [],\n",
    "    'melhor_params': []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1c8ab0",
   "metadata": {},
   "source": [
    "Um exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d72797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop de treinamento com otimiza√ß√£o de hiperpar√¢metros\n",
    "    \n",
    "    # Medir tempo de execu√ß√£o\n",
    "    inicio = time.time()\n",
    "    \n",
    "    # Grid Search com valida√ß√£o cruzada\n",
    "    try:\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=config['estimador'],\n",
    "            param_grid=config['params_grid'],\n",
    "            cv=cv_folds,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Treinar com grid search\n",
    "        grid_search.fit(X_train_scaled, y_train_encoded)\n",
    "        \n",
    "        # Melhor modelo\n",
    "        melhor_modelo = grid_search.best_estimator_\n",
    "        \n",
    "        # Avalia√ß√£o com valida√ß√£o cruzada\n",
    "        scores_cv = cross_val_score(\n",
    "            melhor_modelo, X_train_scaled, y_train_encoded, \n",
    "            cv=cv_folds, scoring='accuracy'\n",
    "        )\n",
    "        \n",
    "        # Previs√µes no conjunto de teste\n",
    "        y_pred = melhor_modelo.predict(X_test_scaled)\n",
    "        acuracia_teste = accuracy_score(y_test_encoded, y_pred)\n",
    "        \n",
    "        # Tempo de execu√ß√£o\n",
    "        tempo_execucao = time.time() - inicio\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        resultados['modelo'].append(nome)\n",
    "        resultados['acuracia_cv'].append(scores_cv.mean())\n",
    "        resultados['std_cv'].append(scores_cv.std())\n",
    "        resultados['acuracia_teste'].append(acuracia_teste)\n",
    "        resultados['tempo_treino'].append(tempo_execucao)\n",
    "        resultados['melhor_params'].append(grid_search.best_params_)\n",
    "        \n",
    "        # Mostrar progresso\n",
    "        print(f\"  ‚úÖ Conclu√≠do em {tempo_execucao:.2f}s\")\n",
    "        print(f\"  üìä CV Accuracy: {scores_cv.mean():.4f} (¬±{scores_cv.std():.4f})\")\n",
    "        print(f\"  üéØ Test Accuracy: {acuracia_teste:.4f}\")\n",
    "        print(f\"  ‚öôÔ∏è Melhores par√¢metros: {grid_search.best_params_}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Erro no treinamento: {str(e)}\")\n",
    "        # Adicionar valores padr√£o em caso de erro\n",
    "        resultados['modelo'].append(nome)\n",
    "        resultados['acuracia_cv'].append(0.0)\n",
    "        resultados['std_cv'].append(0.0)\n",
    "        resultados['acuracia_teste'].append(0.0)\n",
    "        resultados['tempo_treino'].append(0.0)\n",
    "        resultados['melhor_params'].append({})\n",
    "\n",
    "print(f\"\\nüèÅ Treinamento conclu√≠do!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Criar DataFrame com resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values('acuracia_teste', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dc6ae5",
   "metadata": {},
   "source": [
    "## 4. Avalia√ß√£o Detalhada dos Modelos\n",
    "Gerar os gr√°ficos (nesse c√≥digo ele est√° comparando valores, √© s√≥ um exemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db13e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√µes comparativas\n",
    "\n",
    "# 1. Gr√°fico de barras - Acur√°cia\n",
    "axes[0, 0].bar(range(len(df_resultados)), df_resultados['acuracia_teste'], \n",
    "               color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'], alpha=0.8)\n",
    "axes[0, 0].set_title('üéØ Acur√°cia no Conjunto de Teste', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Acur√°cia')\n",
    "axes[0, 0].set_xticks(range(len(df_resultados)))\n",
    "axes[0, 0].set_xticklabels([m.replace('üå≤ ', '').replace('üöÄ ', '').replace('üìè ', '').replace('üìä ', '').replace('üß† ', '') \n",
    "                           for m in df_resultados['modelo']], rotation=45, ha='right')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "for i, v in enumerate(df_resultados['acuracia_teste']):\n",
    "    axes[0, 0].text(i, v + 0.005, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Valida√ß√£o Cruzada com barras de erro\n",
    "x_pos = range(len(df_resultados))\n",
    "axes[0, 1].bar(x_pos, df_resultados['acuracia_cv'], \n",
    "               yerr=df_resultados['std_cv'], capsize=5,\n",
    "               color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'], alpha=0.8)\n",
    "axes[0, 1].set_title('üìä Valida√ß√£o Cruzada (5-fold)', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Acur√°cia CV')\n",
    "axes[0, 1].set_xticks(x_pos)\n",
    "axes[0, 1].set_xticklabels([m.replace('üå≤ ', '').replace('üöÄ ', '').replace('üìè ', '').replace('üìä ', '').replace('üß† ', '') \n",
    "                           for m in df_resultados['modelo']], rotation=45, ha='right')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Tempo de treinamento\n",
    "axes[1, 0].bar(range(len(df_resultados)), df_resultados['tempo_treino'], \n",
    "               color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'], alpha=0.8)\n",
    "axes[1, 0].set_title('‚è±Ô∏è Tempo de Treinamento', fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Tempo (segundos)')\n",
    "axes[1, 0].set_xticks(range(len(df_resultados)))\n",
    "axes[1, 0].set_xticklabels([m.replace('üå≤ ', '').replace('üöÄ ', '').replace('üìè ', '').replace('üìä ', '').replace('üß† ', '') \n",
    "                           for m in df_resultados['modelo']], rotation=45, ha='right')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "for i, v in enumerate(df_resultados['tempo_treino']):\n",
    "    axes[1, 0].text(i, v + max(df_resultados['tempo_treino'])*0.01, f'{v:.1f}s', \n",
    "                    ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 4. Compara√ß√£o Acur√°cia vs Tempo\n",
    "scatter = axes[1, 1].scatter(df_resultados['tempo_treino'], df_resultados['acuracia_teste'], \n",
    "                            s=200, alpha=0.7, c=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'])\n",
    "axes[1, 1].set_title('‚öñÔ∏è Acur√°cia vs Tempo de Treinamento', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Tempo de Treinamento (s)')\n",
    "axes[1, 1].set_ylabel('Acur√°cia')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Adicionar labels aos pontos\n",
    "for i, (x, y, nome) in enumerate(zip(df_resultados['tempo_treino'], \n",
    "                                    df_resultados['acuracia_teste'], \n",
    "                                    df_resultados['modelo'])):\n",
    "    nome_curto = nome.replace('üå≤ ', '').replace('üöÄ ', '').replace('üìè ', '').replace('üìä ', '').replace('üß† ', '')\n",
    "    axes[1, 1].annotate(nome_curto, (x, y), xytext=(5, 5), textcoords='offset points',\n",
    "                       fontsize=9, ha='left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tabela resumo\n",
    "print(\"üìã TABELA RESUMO DOS RESULTADOS:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Modelo':<20} {'Acur√°cia CV':<12} {'Std CV':<10} {'Acur√°cia Teste':<15} {'Tempo (s)':<10}\")\n",
    "print(\"-\" * 80)\n",
    "for _, row in df_resultados.iterrows():\n",
    "    nome_limpo = row['modelo'].replace('üå≤ ', '').replace('üöÄ ', '').replace('üìè ', '').replace('üìä ', '').replace('üß† ', '')\n",
    "    print(f\"{nome_limpo:<20} {row['acuracia_cv']:<12.4f} {row['std_cv']:<10.4f} {row['acuracia_teste']:<15.4f} {row['tempo_treino']:<10.2f}\")\n",
    "\n",
    "print(\"\\nüèÜ MELHOR MODELO:\", df_resultados.iloc[0]['modelo'])\n",
    "print(f\"   üéØ Acur√°cia: {df_resultados.iloc[0]['acuracia_teste']:.4f}\")\n",
    "print(f\"   ‚öôÔ∏è  Par√¢metros: {df_resultados.iloc[0]['melhor_params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852025f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise detalhada do melhor modelo\n",
    "melhor_modelo_nome = df_resultados.iloc[0]['modelo']\n",
    "melhor_params = df_resultados.iloc[0]['melhor_params']\n",
    "\n",
    "print(f\"üîç AN√ÅLISE DETALHADA - {melhor_modelo_nome}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Retreinar o melhor modelo para an√°lise detalhada\n",
    "melhor_config = modelos[melhor_modelo_nome]\n",
    "modelo_final = melhor_config['estimador'].set_params(**melhor_params)\n",
    "modelo_final.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "# Previs√µes\n",
    "y_pred_final = modelo_final.predict(X_test_scaled)\n",
    "y_pred_proba = modelo_final.predict_proba(X_test_scaled) if hasattr(modelo_final, 'predict_proba') else None\n",
    "\n",
    "# Matriz de confus√£o\n",
    "cm = confusion_matrix(y_test_encoded, y_pred_final)\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# Visualiza√ß√£o da matriz de confus√£o\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'N√∫mero de Amostras'})\n",
    "plt.title(f'üéØ Matriz de Confus√£o - {melhor_modelo_nome}', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Classe Predita', fontweight='bold')\n",
    "plt.ylabel('Classe Real', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Relat√≥rio de classifica√ß√£o\n",
    "print(f\"\\nüìä RELAT√ìRIO DE CLASSIFICA√á√ÉO:\")\n",
    "print(\"=\" * 50)\n",
    "report = classification_report(y_test_encoded, y_pred_final, \n",
    "                             target_names=class_names, output_dict=True)\n",
    "\n",
    "# Exibir m√©tricas por classe\n",
    "for classe in class_names:\n",
    "    metrics = report[classe]\n",
    "    print(f\"\\nüè∑Ô∏è  Classe '{classe}':\")\n",
    "    print(f\"   Precis√£o:  {metrics['precision']:.4f}\")\n",
    "    print(f\"   Recall:    {metrics['recall']:.4f}\")\n",
    "    print(f\"   F1-Score:  {metrics['f1-score']:.4f}\")\n",
    "    print(f\"   Suporte:   {metrics['support']:.0f} amostras\")\n",
    "\n",
    "# M√©tricas globais\n",
    "print(f\"\\nüåê M√âTRICAS GLOBAIS:\")\n",
    "print(f\"   Acur√°cia:     {report['accuracy']:.4f}\")\n",
    "print(f\"   Macro Avg:    {report['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"   Weighted Avg: {report['weighted avg']['f1-score']:.4f}\")\n",
    "\n",
    "# An√°lise de erro por classe\n",
    "print(f\"\\n‚ùå AN√ÅLISE DE ERROS:\")\n",
    "print(\"=\" * 30)\n",
    "for i, classe_real in enumerate(class_names):\n",
    "    for j, classe_pred in enumerate(class_names):\n",
    "        if i != j and cm[i, j] > 0:\n",
    "            taxa_erro = cm[i, j] / cm[i, :].sum() * 100\n",
    "            print(f\"   {classe_real} ‚Üí {classe_pred}: {cm[i, j]} erros ({taxa_erro:.1f}%)\")\n",
    "\n",
    "# Calcular m√©tricas adicionais\n",
    "print(f\"\\nüìà M√âTRICAS ADICIONAIS:\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Precis√£o balanceada\n",
    "balanced_acc = balanced_accuracy_score(y_test_encoded, y_pred_final)\n",
    "print(f\"   Acur√°cia Balanceada: {balanced_acc:.4f}\")\n",
    "\n",
    "# Kappa de Cohen\n",
    "kappa = cohen_kappa_score(y_test_encoded, y_pred_final)\n",
    "print(f\"   Kappa de Cohen: {kappa:.4f}\")\n",
    "\n",
    "# MCC (Matthews Correlation Coefficient) - apenas para classifica√ß√£o bin√°ria\n",
    "if len(class_names) == 2:\n",
    "    mcc = matthews_corrcoef(y_test_encoded, y_pred_final)\n",
    "    print(f\"   Matthews Correlation: {mcc:.4f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ An√°lise do melhor modelo conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf749243",
   "metadata": {},
   "source": [
    "## 5. Conclus√µes\n",
    "\n",
    "### üéØ Principais Descobertas\n",
    "\n",
    "1. **Trade-offs**:\n",
    "2. **Robustez**:\n",
    "3. **Otimiza√ß√£o**:\n",
    "\n",
    "### üìä M√©tricas Importantes\n",
    "\n",
    "- \n",
    "\n",
    "\n",
    "### üíæ Salvamento do Modelo\n",
    "\n",
    "O melhor modelo ser√° salvo para uso futuro e implementa√ß√£o em produ√ß√£o."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
