{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8988e0",
   "metadata": {},
   "source": [
    "# Projeto de Sinais e Sistemas para Computa√ß√£o (SSC)\n",
    "\n",
    "## III - Algoritmo de Classifica√ß√£o\n",
    "\n",
    "Este notebook implementa o algoritmo de classifica√ß√£o:\n",
    "- **Random Forest**\n",
    "\n",
    "### Objetivos:\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae1d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necess√°rios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e98005",
   "metadata": {},
   "source": [
    "## 1. Carregamento e Prepara√ß√£o dos Dados\n",
    "\n",
    "Carregamos o dataset de caracter√≠sticas gerado no notebook anterior e preparamos os dados para classifica√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee50d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad67ea4e",
   "metadata": {},
   "source": [
    "## 2. Pr√©-processamento dos Dados\n",
    "\n",
    "Preparamos os dados para os algoritmos de classifica√ß√£o: divis√£o treino/teste, normaliza√ß√£o e codifica√ß√£o de labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33810479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e22d337",
   "metadata": {},
   "source": [
    "## 3. Implementa√ß√£o dos Algoritmos de Classifica√ß√£o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f827c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar modelos com hiperpar√¢metros otimizados\n",
    "modelos = {\n",
    "    'üå≤ Random Forest': {\n",
    "        'estimador': RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        'params_grid': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [5, 10, 15, None],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Dicion√°rio para armazenar resultados\n",
    "resultados = {\n",
    "    'modelo': [],\n",
    "    'acuracia_cv': [],\n",
    "    'std_cv': [],\n",
    "    'acuracia_teste': [],\n",
    "    'tempo_treino': [],\n",
    "    'melhor_params': []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1c8ab0",
   "metadata": {},
   "source": [
    "Um exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d72797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop de treinamento com otimiza√ß√£o de hiperpar√¢metros\n",
    "    \n",
    "    # Medir tempo de execu√ß√£o\n",
    "    inicio = time.time()\n",
    "    \n",
    "    # Grid Search com valida√ß√£o cruzada\n",
    "    try:\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=config['estimador'],\n",
    "            param_grid=config['params_grid'],\n",
    "            cv=cv_folds,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Treinar com grid search\n",
    "        grid_search.fit(X_train_scaled, y_train_encoded)\n",
    "        \n",
    "        # Melhor modelo\n",
    "        melhor_modelo = grid_search.best_estimator_\n",
    "        \n",
    "        # Avalia√ß√£o com valida√ß√£o cruzada\n",
    "        scores_cv = cross_val_score(\n",
    "            melhor_modelo, X_train_scaled, y_train_encoded, \n",
    "            cv=cv_folds, scoring='accuracy'\n",
    "        )\n",
    "        \n",
    "        # Previs√µes no conjunto de teste\n",
    "        y_pred = melhor_modelo.predict(X_test_scaled)\n",
    "        acuracia_teste = accuracy_score(y_test_encoded, y_pred)\n",
    "        \n",
    "        # Tempo de execu√ß√£o\n",
    "        tempo_execucao = time.time() - inicio\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        resultados['modelo'].append(nome)\n",
    "        resultados['acuracia_cv'].append(scores_cv.mean())\n",
    "        resultados['std_cv'].append(scores_cv.std())\n",
    "        resultados['acuracia_teste'].append(acuracia_teste)\n",
    "        resultados['tempo_treino'].append(tempo_execucao)\n",
    "        resultados['melhor_params'].append(grid_search.best_params_)\n",
    "        \n",
    "        # Mostrar progresso\n",
    "        print(f\"  ‚úÖ Conclu√≠do em {tempo_execucao:.2f}s\")\n",
    "        print(f\"  üìä CV Accuracy: {scores_cv.mean():.4f} (¬±{scores_cv.std():.4f})\")\n",
    "        print(f\"  üéØ Test Accuracy: {acuracia_teste:.4f}\")\n",
    "        print(f\"  ‚öôÔ∏è Melhores par√¢metros: {grid_search.best_params_}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Erro no treinamento: {str(e)}\")\n",
    "        # Adicionar valores padr√£o em caso de erro\n",
    "        resultados['modelo'].append(nome)\n",
    "        resultados['acuracia_cv'].append(0.0)\n",
    "        resultados['std_cv'].append(0.0)\n",
    "        resultados['acuracia_teste'].append(0.0)\n",
    "        resultados['tempo_treino'].append(0.0)\n",
    "        resultados['melhor_params'].append({})\n",
    "\n",
    "print(f\"\\nüèÅ Treinamento conclu√≠do!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Criar DataFrame com resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values('acuracia_teste', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dc6ae5",
   "metadata": {},
   "source": [
    "## 4. Avalia√ß√£o Detalhada dos Modelos\n",
    "Gerar os gr√°ficos (nesse c√≥digo ele est√° comparando valores, √© s√≥ um exemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db13e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√µes comparativas\n",
    "\n",
    "# 1. Gr√°fico de barras - Acur√°cia\n",
    "axes[0, 0].bar(range(len(df_resultados)), df_resultados['acuracia_teste'], \n",
    "               color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'], alpha=0.8)\n",
    "axes[0, 0].set_title('üéØ Acur√°cia no Conjunto de Teste', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Acur√°cia')\n",
    "axes[0, 0].set_xticks(range(len(df_resultados)))\n",
    "axes[0, 0].set_xticklabels([m.replace('üå≤ ', '').replace('üöÄ ', '').replace('üìè ', '').replace('üìä ', '').replace('üß† ', '') \n",
    "                           for m in df_resultados['modelo']], rotation=45, ha='right')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "for i, v in enumerate(df_resultados['acuracia_teste']):\n",
    "    axes[0, 0].text(i, v + 0.005, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Valida√ß√£o Cruzada com barras de erro\n",
    "x_pos = range(len(df_resultados))\n",
    "axes[0, 1].bar(x_pos, df_resultados['acuracia_cv'], \n",
    "               yerr=df_resultados['std_cv'], capsize=5,\n",
    "               color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'], alpha=0.8)\n",
    "axes[0, 1].set_title('üìä Valida√ß√£o Cruzada (5-fold)', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Acur√°cia CV')\n",
    "axes[0, 1].set_xticks(x_pos)\n",
    "axes[0, 1].set_xticklabels([m.replace('üå≤ ', '').replace('üöÄ ', '').replace('üìè ', '').replace('üìä ', '').replace('üß† ', '') \n",
    "                           for m in df_resultados['modelo']], rotation=45, ha='right')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Tempo de treinamento\n",
    "axes[1, 0].bar(range(len(df_resultados)), df_resultados['tempo_treino'], \n",
    "               color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'], alpha=0.8)\n",
    "axes[1, 0].set_title('‚è±Ô∏è Tempo de Treinamento', fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Tempo (segundos)')\n",
    "axes[1, 0].set_xticks(range(len(df_resultados)))\n",
    "axes[1, 0].set_xticklabels([m.replace('üå≤ ', '').replace('üöÄ ', '').replace('üìè ', '').replace('üìä ', '').replace('üß† ', '') \n",
    "                           for m in df_resultados['modelo']], rotation=45, ha='right')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "for i, v in enumerate(df_resultados['tempo_treino']):\n",
    "    axes[1, 0].text(i, v + max(df_resultados['tempo_treino'])*0.01, f'{v:.1f}s', \n",
    "                    ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 4. Compara√ß√£o Acur√°cia vs Tempo\n",
    "scatter = axes[1, 1].scatter(df_resultados['tempo_treino'], df_resultados['acuracia_teste'], \n",
    "                            s=200, alpha=0.7, c=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'])\n",
    "axes[1, 1].set_title('‚öñÔ∏è Acur√°cia vs Tempo de Treinamento', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Tempo de Treinamento (s)')\n",
    "axes[1, 1].set_ylabel('Acur√°cia')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Adicionar labels aos pontos\n",
    "for i, (x, y, nome) in enumerate(zip(df_resultados['tempo_treino'], \n",
    "                                    df_resultados['acuracia_teste'], \n",
    "                                    df_resultados['modelo'])):\n",
    "    nome_curto = nome.replace('üå≤ ', '').replace('üöÄ ', '').replace('üìè ', '').replace('üìä ', '').replace('üß† ', '')\n",
    "    axes[1, 1].annotate(nome_curto, (x, y), xytext=(5, 5), textcoords='offset points',\n",
    "                       fontsize=9, ha='left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tabela resumo\n",
    "print(\"üìã TABELA RESUMO DOS RESULTADOS:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Modelo':<20} {'Acur√°cia CV':<12} {'Std CV':<10} {'Acur√°cia Teste':<15} {'Tempo (s)':<10}\")\n",
    "print(\"-\" * 80)\n",
    "for _, row in df_resultados.iterrows():\n",
    "    nome_limpo = row['modelo'].replace('üå≤ ', '').replace('üöÄ ', '').replace('üìè ', '').replace('üìä ', '').replace('üß† ', '')\n",
    "    print(f\"{nome_limpo:<20} {row['acuracia_cv']:<12.4f} {row['std_cv']:<10.4f} {row['acuracia_teste']:<15.4f} {row['tempo_treino']:<10.2f}\")\n",
    "\n",
    "print(\"\\nüèÜ MELHOR MODELO:\", df_resultados.iloc[0]['modelo'])\n",
    "print(f\"   üéØ Acur√°cia: {df_resultados.iloc[0]['acuracia_teste']:.4f}\")\n",
    "print(f\"   ‚öôÔ∏è  Par√¢metros: {df_resultados.iloc[0]['melhor_params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852025f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise detalhada do melhor modelo\n",
    "melhor_modelo_nome = df_resultados.iloc[0]['modelo']\n",
    "melhor_params = df_resultados.iloc[0]['melhor_params']\n",
    "\n",
    "print(f\"üîç AN√ÅLISE DETALHADA - {melhor_modelo_nome}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Retreinar o melhor modelo para an√°lise detalhada\n",
    "melhor_config = modelos[melhor_modelo_nome]\n",
    "modelo_final = melhor_config['estimador'].set_params(**melhor_params)\n",
    "modelo_final.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "# Previs√µes\n",
    "y_pred_final = modelo_final.predict(X_test_scaled)\n",
    "y_pred_proba = modelo_final.predict_proba(X_test_scaled) if hasattr(modelo_final, 'predict_proba') else None\n",
    "\n",
    "# Matriz de confus√£o\n",
    "cm = confusion_matrix(y_test_encoded, y_pred_final)\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# Visualiza√ß√£o da matriz de confus√£o\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'N√∫mero de Amostras'})\n",
    "plt.title(f'üéØ Matriz de Confus√£o - {melhor_modelo_nome}', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Classe Predita', fontweight='bold')\n",
    "plt.ylabel('Classe Real', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Relat√≥rio de classifica√ß√£o\n",
    "print(f\"\\nüìä RELAT√ìRIO DE CLASSIFICA√á√ÉO:\")\n",
    "print(\"=\" * 50)\n",
    "report = classification_report(y_test_encoded, y_pred_final, \n",
    "                             target_names=class_names, output_dict=True)\n",
    "\n",
    "# Exibir m√©tricas por classe\n",
    "for classe in class_names:\n",
    "    metrics = report[classe]\n",
    "    print(f\"\\nüè∑Ô∏è  Classe '{classe}':\")\n",
    "    print(f\"   Precis√£o:  {metrics['precision']:.4f}\")\n",
    "    print(f\"   Recall:    {metrics['recall']:.4f}\")\n",
    "    print(f\"   F1-Score:  {metrics['f1-score']:.4f}\")\n",
    "    print(f\"   Suporte:   {metrics['support']:.0f} amostras\")\n",
    "\n",
    "# M√©tricas globais\n",
    "print(f\"\\nüåê M√âTRICAS GLOBAIS:\")\n",
    "print(f\"   Acur√°cia:     {report['accuracy']:.4f}\")\n",
    "print(f\"   Macro Avg:    {report['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"   Weighted Avg: {report['weighted avg']['f1-score']:.4f}\")\n",
    "\n",
    "# An√°lise de erro por classe\n",
    "print(f\"\\n‚ùå AN√ÅLISE DE ERROS:\")\n",
    "print(\"=\" * 30)\n",
    "for i, classe_real in enumerate(class_names):\n",
    "    for j, classe_pred in enumerate(class_names):\n",
    "        if i != j and cm[i, j] > 0:\n",
    "            taxa_erro = cm[i, j] / cm[i, :].sum() * 100\n",
    "            print(f\"   {classe_real} ‚Üí {classe_pred}: {cm[i, j]} erros ({taxa_erro:.1f}%)\")\n",
    "\n",
    "# Calcular m√©tricas adicionais\n",
    "print(f\"\\nüìà M√âTRICAS ADICIONAIS:\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Precis√£o balanceada\n",
    "balanced_acc = balanced_accuracy_score(y_test_encoded, y_pred_final)\n",
    "print(f\"   Acur√°cia Balanceada: {balanced_acc:.4f}\")\n",
    "\n",
    "# Kappa de Cohen\n",
    "kappa = cohen_kappa_score(y_test_encoded, y_pred_final)\n",
    "print(f\"   Kappa de Cohen: {kappa:.4f}\")\n",
    "\n",
    "# MCC (Matthews Correlation Coefficient) - apenas para classifica√ß√£o bin√°ria\n",
    "if len(class_names) == 2:\n",
    "    mcc = matthews_corrcoef(y_test_encoded, y_pred_final)\n",
    "    print(f\"   Matthews Correlation: {mcc:.4f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ An√°lise do melhor modelo conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf749243",
   "metadata": {},
   "source": [
    "## 5. Conclus√µes\n",
    "\n",
    "### üéØ Principais Descobertas\n",
    "\n",
    "1. **Trade-offs**:\n",
    "2. **Robustez**:\n",
    "3. **Otimiza√ß√£o**:\n",
    "\n",
    "### üìä M√©tricas Importantes\n",
    "\n",
    "- \n",
    "\n",
    "\n",
    "### üíæ Salvamento do Modelo\n",
    "\n",
    "O melhor modelo ser√° salvo para uso futuro e implementa√ß√£o em produ√ß√£o."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
