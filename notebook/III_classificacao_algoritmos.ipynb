{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8988e0",
   "metadata": {},
   "source": [
    "# Projeto de Sinais e Sistemas para Computação (SSC)\n",
    "\n",
    "## III - Algoritmo de Classificação\n",
    "\n",
    "Este notebook implementa o algoritmo de classificação:\n",
    "- **Random Forest**\n",
    "\n",
    "### Objetivos:\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae1d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necessários\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddd6500-902d-4460-a525-b7fa339b55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testes básicos com base no que o gpt mandou\n",
    "# que seria criar um modelo para doença, pois as doenças nao são necessariamente classes excludentes\n",
    "# cada linha do features é de uma derivação de um paciente x, ele sugeriu unir tudo em uma única linha de \n",
    "# um dataframe para treinar, basicamente criar uma matrix com todos os dados de uma derivação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c946c0-fcbd-41ad-8452-b59729502311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3011c833-59a4-4f82-9a80-919652061455",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "data_path = \"../data/\"\n",
    "qtd_linhas_teste = 12 * 10000 # apenas 5 ecg diferentes, pois cada um ten 12 derivações\n",
    "df = pd.read_csv(data_path + \"features/features_dataset_completo_20250805_001604.csv\", nrows=qtd_linhas_teste)\n",
    "# ordenar o paciente pelo paciente e depois pela derivacao para ter certeza \n",
    "df = df.sort_values([\"ecg_id\", \"canal\"])\n",
    "colunas_descartar_df = [\"canal\", \"fs\", \"n_samples\", \"arquivo_origem\"]\n",
    "# tirando isso pois o canal se reprete(a ideia é juntar todas as derivações em uma linha), o fs e o n_samples nao parecem adicionar nada de info\n",
    "df_f = df.drop(columns=colunas_descartar_df) # agrupa por paciente\n",
    "df_f = df_f.groupby(\"ecg_id\")\n",
    "pacientes = []\n",
    "for i, j in df_f: # i = nome do arquivo e j = conjunto de linhas(incluem o nome do arquivo ainda)\n",
    "    features = j.drop(columns=[\"ecg_id\"])\n",
    "    array_paciente = features.values.flatten()\n",
    "    # print(i, array_paciente, array_paciente.shape) # o shape é (21 * 12), 21 colunas depois das eliminadas e 12 derivaçoes\n",
    "    pacientes.append((i, array_paciente))\n",
    "\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59fb3192-cd1e-4d26-bc27-8c0b6be4d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f82c7a1-f07d-4944-bc76-59aafa779efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pegando o Y database com base nas linhas testes\n",
    "pacientes_ids = []\n",
    "for i in pacientes:\n",
    "    pacientes_ids.append(i[0])\n",
    "# print(\"pacientes =\", pacientes_ids)\n",
    "# filtrar apenas os dados pegos\n",
    "df_dados = pd.read_csv(data_path + \"raw/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/ptbxl_database.csv\")\n",
    "# ele vai printar um index de coluna 1 a mais pois o df ele esta mostrando o idx da linhas e ele começa com 0\n",
    "y = df_dados[df_dados[\"ecg_id\"].isin(pacientes_ids)][\"scp_codes\"].values\n",
    "y_evaled = [ast.literal_eval(item) for item in y]\n",
    "len(y_evaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e891b3-56fe-453b-a6f9-faefc4a9705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"NORM\", \"SR\", \"IMI\"] # so de teste, seria um modelo para cada um desses\n",
    "modelos = {}\n",
    "for i in classes:\n",
    "    # para cada classe ele pega a % de cada paciente, mas colocando de forma binária\n",
    "    # apenas 1 ou 0, melhorar isso, pois isso é so o basico, o gpt ja alertou\n",
    "    '''\n",
    "    Isso cria um vetor binário (0 ou 1) para cada doença.\n",
    "    Se uma doença não tiver nenhum caso positivo no conjunto de teste (ou no treino), o modelo nunca vai prever 1 e o cálculo de precision vai dar problema.\n",
    "    ele sugere isso\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    [f for _, f in pacientes],\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=Y  # garante proporção de 0 e 1 nos dois conjuntos\n",
    "    )\n",
    "    '''\n",
    "    Y = np.array([1 if d.get(i, 0.0) > 0 else 0 for d in y_evaled])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        np.array([f for _, f in pacientes]), Y, test_size=0.2, random_state=42\n",
    "    ) # esse for basicamente pega apenas a matrx\n",
    "\n",
    "\n",
    "    '''\n",
    "    Doenças raras são um desafio.\n",
    "    Se você deixar o RandomForest \"solto\", ele pode prever sempre 0 e ainda assim ter uma alta acurácia.\n",
    "    O que ajuda:\n",
    "    clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    class_weight=\"balanced\",  # ajusta pesos automaticamente\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "    Parâmetros mais importantes e seu efeito\n",
    "    Parâmetro\tO que faz\tImpacto principal\n",
    "    n_estimators\tNúmero de árvores na floresta\tMais árvores = mais robusto, melhor precisão, mas mais tempo de treino e predição. Geralmente usar 100+ é um bom ponto inicial.\n",
    "    max_depth\tProfundidade máxima de cada árvore\tLimita complexidade; controla overfitting. Muito fundo = árvores complexas, risco de overfitting; muito raso = underfitting.\n",
    "    min_samples_split\tMínimo número de amostras para dividir um nó\tControla o quão “exigente” é para dividir nós. Valores maiores reduzem overfitting.\n",
    "    min_samples_leaf\tMínimo número de amostras que um nó folha deve ter\tEvita que a árvore crie folhas muito pequenas, ajudando a generalizar melhor.\n",
    "    max_features\tNúmero máximo de features consideradas para divisão em cada nó\tControla a aleatoriedade. Valores menores aumentam variância entre árvores, ajudando a generalizar. Pode ser int, float ou “auto”, “sqrt”, “log2”.\n",
    "    bootstrap\tSe as amostras para construir cada árvore são sorteadas com reposição\tTrue (default) = amostragem com reposição, aumenta diversidade entre árvores. False usa o dataset todo.\n",
    "    class_weight\tAjusta pesos das classes para balancear dados desbalanceados\tPode ser “balanced”, “balanced_subsample” ou um dict. Ajuda em problemas com classes muito desiguais.\n",
    "    random_state\tSemente do gerador de números aleatórios\tGarante resultados reproduzíveis. Usar valor fixo para repetir experimento.\n",
    "    n_jobs\tNúmero de CPUs usados para o treino\t-1 usa todos os núcleos, acelera o treino.\n",
    "    max_samples\tProporção (ou número) máximo de amostras para treinar cada árvore (usado com bootstrap=True)\tControla tamanho da amostra bootstrap, pode reduzir overfitting.\n",
    "    \n",
    "    Como esses parâmetros influenciam o modelo\n",
    "    Exemplo prático:\n",
    "    Aumentar n_estimators: melhora desempenho (menos variância), mas tempo aumenta linearmente.\n",
    "    \n",
    "    Ajustar max_depth: ajuda a controlar overfitting, especialmente em datasets pequenos ou ruidosos.\n",
    "    \n",
    "    min_samples_split e min_samples_leaf: aumentam a generalização evitando árvores muito complexas.\n",
    "    \n",
    "    max_features menor: aumenta diversidade das árvores e pode melhorar generalização.\n",
    "    \n",
    "    class_weight='balanced': essencial para dados com classes desbalanceadas, melhora performance em classes minoritárias.\n",
    "    \n",
    "    bootstrap=False: menos diversidade, pode levar a overfitting.\n",
    "    \n",
    "    random_state: só para garantir que resultados sejam iguais em execuções diferentes.\n",
    "\n",
    "    \n",
    "    '''\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)    \n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    '''\n",
    "    No caso de classes desbalanceadas, accuracy engana.\n",
    "    Você já usa classification_report, mas pode também monitorar:\n",
    "    \n",
    "    f1-score (mais robusto com desbalanceamento)\n",
    "    \n",
    "    roc_auc_score para binários\n",
    "    '''\n",
    "    print(f\"Acurácia de doenca({i}):\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    modelos[i] = clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8038d2-6e11-4cc5-b789-19bec2f209c4",
   "metadata": {},
   "source": [
    "Pergunta ao gpt:\n",
    "estou trabalhando com doenças cardiacas e os % de classificação são de classes que as vezes batem sendo iguais como posso relacionar, tipo, classe x é subclasse de y ou vice versa, se ele identificar como x ou y ele identifica com a outra, e como posso passar um sinal por todos eles e conseguir todas essas classificações\n",
    "\n",
    "Resultado:\n",
    "1️⃣ Modelagem de classes hierárquicas ou relacionadas\n",
    "a) Definir uma hierarquia ou rede de relações\n",
    "Você pode criar uma estrutura que mostra relações entre as classes, por exemplo:\n",
    "\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "relacoes = {\n",
    "    \"doenca_y\": [\"doenca_x\", \"doenca_z\"],  # doenca_x e doenca_z são subclasses de doenca_y\n",
    "    \"doenca_x\": [],\n",
    "    \"doenca_z\": [],\n",
    "    # outras classes ...\n",
    "}\n",
    "Ou se preferir, um grafo (usando networkx) para relações mais complexas.\n",
    "\n",
    "b) Regra de associação entre classes relacionadas\n",
    "Por exemplo, se o modelo identificar doenca_x com alta chance, você automaticamente considera doenca_y presente (porque é pai/mais geral).\n",
    "\n",
    "2️⃣ Como passar um sinal e obter as classificações\n",
    "Supondo que você tenha modelos binários para várias doenças (como fez com Random Forest), você pode:\n",
    "\n",
    "Passar o vetor de features do paciente para todos os modelos.\n",
    "\n",
    "Obter as previsões (probabilidades ou classes).\n",
    "\n",
    "Aplicar a regra de hierarquia para \"expandir\" ou \"relacionar\" resultados.\n",
    "\n",
    "Exemplo simplificado:\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "# Modelos binários treinados para cada doença\n",
    "modelos = {\n",
    "    \"doenca_x\": modelo_x,\n",
    "    \"doenca_y\": modelo_y,\n",
    "    # ...\n",
    "}\n",
    "\n",
    "relacoes = {\n",
    "    \"doenca_y\": [\"doenca_x\"],  # doenca_x é subclasse de doenca_y\n",
    "    \"doenca_x\": [],\n",
    "}\n",
    "\n",
    "def prever_com_relacoes(features, modelos, relacoes):\n",
    "    preds = {}\n",
    "    for doenca, modelo in modelos.items():\n",
    "        preds[doenca] = modelo.predict(features.reshape(1, -1))[0]\n",
    "\n",
    "    # Propagar presença para classes pais\n",
    "    for pai, filhos in relacoes.items():\n",
    "        if any(preds.get(filho, 0) == 1 for filho in filhos):\n",
    "            preds[pai] = 1  # se algum filho detectado, marca pai como presente\n",
    "\n",
    "    return preds\n",
    "\n",
    "# Usar:\n",
    "resultado = prever_com_relacoes(X_paciente, modelos, relacoes)\n",
    "print(resultado)\n",
    "3️⃣ Dicas extras\n",
    "Se suas classes são mutuamente exclusivas em alguns níveis, talvez valha a pena usar modelos hierárquicos (primeiro prever classe geral, depois subclassificar).\n",
    "\n",
    "Para saída probabilística, considere usar o método .predict_proba() para ajustar limiares e combinar evidências.\n",
    "\n",
    "Se quiser, pode usar técnicas de classificação multi-label com dependências entre classes, como classificação hierárquica — há bibliotecas específicas para isso.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e98005",
   "metadata": {},
   "source": [
    "## 1. Carregamento e Preparação dos Dados\n",
    "\n",
    "Carregamos o dataset de características gerado no notebook anterior e preparamos os dados para classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee50d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad67ea4e",
   "metadata": {},
   "source": [
    "## 2. Pré-processamento dos Dados\n",
    "\n",
    "Preparamos os dados para os algoritmos de classificação: divisão treino/teste, normalização e codificação de labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33810479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e22d337",
   "metadata": {},
   "source": [
    "## 3. Implementação dos Algoritmos de Classificação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f827c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar modelos com hiperparâmetros otimizados\n",
    "modelos = {\n",
    "    '🌲 Random Forest': {\n",
    "        'estimador': RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        'params_grid': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [5, 10, 15, None],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Dicionário para armazenar resultados\n",
    "resultados = {\n",
    "    'modelo': [],\n",
    "    'acuracia_cv': [],\n",
    "    'std_cv': [],\n",
    "    'acuracia_teste': [],\n",
    "    'tempo_treino': [],\n",
    "    'melhor_params': []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1c8ab0",
   "metadata": {},
   "source": [
    "Um exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d72797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop de treinamento com otimização de hiperparâmetros\n",
    "    \n",
    "    # Medir tempo de execução\n",
    "    inicio = time.time()\n",
    "    \n",
    "    # Grid Search com validação cruzada\n",
    "    try:\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=config['estimador'],\n",
    "            param_grid=config['params_grid'],\n",
    "            cv=cv_folds,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Treinar com grid search\n",
    "        grid_search.fit(X_train_scaled, y_train_encoded)\n",
    "        \n",
    "        # Melhor modelo\n",
    "        melhor_modelo = grid_search.best_estimator_\n",
    "        \n",
    "        # Avaliação com validação cruzada\n",
    "        scores_cv = cross_val_score(\n",
    "            melhor_modelo, X_train_scaled, y_train_encoded, \n",
    "            cv=cv_folds, scoring='accuracy'\n",
    "        )\n",
    "        \n",
    "        # Previsões no conjunto de teste\n",
    "        y_pred = melhor_modelo.predict(X_test_scaled)\n",
    "        acuracia_teste = accuracy_score(y_test_encoded, y_pred)\n",
    "        \n",
    "        # Tempo de execução\n",
    "        tempo_execucao = time.time() - inicio\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        resultados['modelo'].append(nome)\n",
    "        resultados['acuracia_cv'].append(scores_cv.mean())\n",
    "        resultados['std_cv'].append(scores_cv.std())\n",
    "        resultados['acuracia_teste'].append(acuracia_teste)\n",
    "        resultados['tempo_treino'].append(tempo_execucao)\n",
    "        resultados['melhor_params'].append(grid_search.best_params_)\n",
    "        \n",
    "        # Mostrar progresso\n",
    "        print(f\"  ✅ Concluído em {tempo_execucao:.2f}s\")\n",
    "        print(f\"  📊 CV Accuracy: {scores_cv.mean():.4f} (±{scores_cv.std():.4f})\")\n",
    "        print(f\"  🎯 Test Accuracy: {acuracia_teste:.4f}\")\n",
    "        print(f\"  ⚙️ Melhores parâmetros: {grid_search.best_params_}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Erro no treinamento: {str(e)}\")\n",
    "        # Adicionar valores padrão em caso de erro\n",
    "        resultados['modelo'].append(nome)\n",
    "        resultados['acuracia_cv'].append(0.0)\n",
    "        resultados['std_cv'].append(0.0)\n",
    "        resultados['acuracia_teste'].append(0.0)\n",
    "        resultados['tempo_treino'].append(0.0)\n",
    "        resultados['melhor_params'].append({})\n",
    "\n",
    "print(f\"\\n🏁 Treinamento concluído!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Criar DataFrame com resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values('acuracia_teste', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dc6ae5",
   "metadata": {},
   "source": [
    "## 4. Avaliação Detalhada dos Modelos\n",
    "Gerar os gráficos (nesse código ele está comparando valores, é só um exemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db13e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizações comparativas\n",
    "\n",
    "# 1. Gráfico de barras - Acurácia\n",
    "axes[0, 0].bar(range(len(df_resultados)), df_resultados['acuracia_teste'], \n",
    "               color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'], alpha=0.8)\n",
    "axes[0, 0].set_title('🎯 Acurácia no Conjunto de Teste', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Acurácia')\n",
    "axes[0, 0].set_xticks(range(len(df_resultados)))\n",
    "axes[0, 0].set_xticklabels([m.replace('🌲 ', '').replace('🚀 ', '').replace('📏 ', '').replace('📊 ', '').replace('🧠 ', '') \n",
    "                           for m in df_resultados['modelo']], rotation=45, ha='right')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "for i, v in enumerate(df_resultados['acuracia_teste']):\n",
    "    axes[0, 0].text(i, v + 0.005, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Validação Cruzada com barras de erro\n",
    "x_pos = range(len(df_resultados))\n",
    "axes[0, 1].bar(x_pos, df_resultados['acuracia_cv'], \n",
    "               yerr=df_resultados['std_cv'], capsize=5,\n",
    "               color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'], alpha=0.8)\n",
    "axes[0, 1].set_title('📊 Validação Cruzada (5-fold)', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Acurácia CV')\n",
    "axes[0, 1].set_xticks(x_pos)\n",
    "axes[0, 1].set_xticklabels([m.replace('🌲 ', '').replace('🚀 ', '').replace('📏 ', '').replace('📊 ', '').replace('🧠 ', '') \n",
    "                           for m in df_resultados['modelo']], rotation=45, ha='right')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Tempo de treinamento\n",
    "axes[1, 0].bar(range(len(df_resultados)), df_resultados['tempo_treino'], \n",
    "               color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'], alpha=0.8)\n",
    "axes[1, 0].set_title('⏱️ Tempo de Treinamento', fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Tempo (segundos)')\n",
    "axes[1, 0].set_xticks(range(len(df_resultados)))\n",
    "axes[1, 0].set_xticklabels([m.replace('🌲 ', '').replace('🚀 ', '').replace('📏 ', '').replace('📊 ', '').replace('🧠 ', '') \n",
    "                           for m in df_resultados['modelo']], rotation=45, ha='right')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "for i, v in enumerate(df_resultados['tempo_treino']):\n",
    "    axes[1, 0].text(i, v + max(df_resultados['tempo_treino'])*0.01, f'{v:.1f}s', \n",
    "                    ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 4. Comparação Acurácia vs Tempo\n",
    "scatter = axes[1, 1].scatter(df_resultados['tempo_treino'], df_resultados['acuracia_teste'], \n",
    "                            s=200, alpha=0.7, c=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'])\n",
    "axes[1, 1].set_title('⚖️ Acurácia vs Tempo de Treinamento', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Tempo de Treinamento (s)')\n",
    "axes[1, 1].set_ylabel('Acurácia')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Adicionar labels aos pontos\n",
    "for i, (x, y, nome) in enumerate(zip(df_resultados['tempo_treino'], \n",
    "                                    df_resultados['acuracia_teste'], \n",
    "                                    df_resultados['modelo'])):\n",
    "    nome_curto = nome.replace('🌲 ', '').replace('🚀 ', '').replace('📏 ', '').replace('📊 ', '').replace('🧠 ', '')\n",
    "    axes[1, 1].annotate(nome_curto, (x, y), xytext=(5, 5), textcoords='offset points',\n",
    "                       fontsize=9, ha='left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tabela resumo\n",
    "print(\"📋 TABELA RESUMO DOS RESULTADOS:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Modelo':<20} {'Acurácia CV':<12} {'Std CV':<10} {'Acurácia Teste':<15} {'Tempo (s)':<10}\")\n",
    "print(\"-\" * 80)\n",
    "for _, row in df_resultados.iterrows():\n",
    "    nome_limpo = row['modelo'].replace('🌲 ', '').replace('🚀 ', '').replace('📏 ', '').replace('📊 ', '').replace('🧠 ', '')\n",
    "    print(f\"{nome_limpo:<20} {row['acuracia_cv']:<12.4f} {row['std_cv']:<10.4f} {row['acuracia_teste']:<15.4f} {row['tempo_treino']:<10.2f}\")\n",
    "\n",
    "print(\"\\n🏆 MELHOR MODELO:\", df_resultados.iloc[0]['modelo'])\n",
    "print(f\"   🎯 Acurácia: {df_resultados.iloc[0]['acuracia_teste']:.4f}\")\n",
    "print(f\"   ⚙️  Parâmetros: {df_resultados.iloc[0]['melhor_params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852025f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise detalhada do melhor modelo\n",
    "melhor_modelo_nome = df_resultados.iloc[0]['modelo']\n",
    "melhor_params = df_resultados.iloc[0]['melhor_params']\n",
    "\n",
    "print(f\"🔍 ANÁLISE DETALHADA - {melhor_modelo_nome}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Retreinar o melhor modelo para análise detalhada\n",
    "melhor_config = modelos[melhor_modelo_nome]\n",
    "modelo_final = melhor_config['estimador'].set_params(**melhor_params)\n",
    "modelo_final.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "# Previsões\n",
    "y_pred_final = modelo_final.predict(X_test_scaled)\n",
    "y_pred_proba = modelo_final.predict_proba(X_test_scaled) if hasattr(modelo_final, 'predict_proba') else None\n",
    "\n",
    "# Matriz de confusão\n",
    "cm = confusion_matrix(y_test_encoded, y_pred_final)\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# Visualização da matriz de confusão\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Número de Amostras'})\n",
    "plt.title(f'🎯 Matriz de Confusão - {melhor_modelo_nome}', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Classe Predita', fontweight='bold')\n",
    "plt.ylabel('Classe Real', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Relatório de classificação\n",
    "print(f\"\\n📊 RELATÓRIO DE CLASSIFICAÇÃO:\")\n",
    "print(\"=\" * 50)\n",
    "report = classification_report(y_test_encoded, y_pred_final, \n",
    "                             target_names=class_names, output_dict=True)\n",
    "\n",
    "# Exibir métricas por classe\n",
    "for classe in class_names:\n",
    "    metrics = report[classe]\n",
    "    print(f\"\\n🏷️  Classe '{classe}':\")\n",
    "    print(f\"   Precisão:  {metrics['precision']:.4f}\")\n",
    "    print(f\"   Recall:    {metrics['recall']:.4f}\")\n",
    "    print(f\"   F1-Score:  {metrics['f1-score']:.4f}\")\n",
    "    print(f\"   Suporte:   {metrics['support']:.0f} amostras\")\n",
    "\n",
    "# Métricas globais\n",
    "print(f\"\\n🌐 MÉTRICAS GLOBAIS:\")\n",
    "print(f\"   Acurácia:     {report['accuracy']:.4f}\")\n",
    "print(f\"   Macro Avg:    {report['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"   Weighted Avg: {report['weighted avg']['f1-score']:.4f}\")\n",
    "\n",
    "# Análise de erro por classe\n",
    "print(f\"\\n❌ ANÁLISE DE ERROS:\")\n",
    "print(\"=\" * 30)\n",
    "for i, classe_real in enumerate(class_names):\n",
    "    for j, classe_pred in enumerate(class_names):\n",
    "        if i != j and cm[i, j] > 0:\n",
    "            taxa_erro = cm[i, j] / cm[i, :].sum() * 100\n",
    "            print(f\"   {classe_real} → {classe_pred}: {cm[i, j]} erros ({taxa_erro:.1f}%)\")\n",
    "\n",
    "# Calcular métricas adicionais\n",
    "print(f\"\\n📈 MÉTRICAS ADICIONAIS:\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Precisão balanceada\n",
    "balanced_acc = balanced_accuracy_score(y_test_encoded, y_pred_final)\n",
    "print(f\"   Acurácia Balanceada: {balanced_acc:.4f}\")\n",
    "\n",
    "# Kappa de Cohen\n",
    "kappa = cohen_kappa_score(y_test_encoded, y_pred_final)\n",
    "print(f\"   Kappa de Cohen: {kappa:.4f}\")\n",
    "\n",
    "# MCC (Matthews Correlation Coefficient) - apenas para classificação binária\n",
    "if len(class_names) == 2:\n",
    "    mcc = matthews_corrcoef(y_test_encoded, y_pred_final)\n",
    "    print(f\"   Matthews Correlation: {mcc:.4f}\")\n",
    "\n",
    "print(f\"\\n✅ Análise do melhor modelo concluída!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf749243",
   "metadata": {},
   "source": [
    "## 5. Conclusões\n",
    "\n",
    "### 🎯 Principais Descobertas\n",
    "\n",
    "1. **Trade-offs**:\n",
    "2. **Robustez**:\n",
    "3. **Otimização**:\n",
    "\n",
    "### 📊 Métricas Importantes\n",
    "\n",
    "- \n",
    "\n",
    "\n",
    "### 💾 Salvamento do Modelo\n",
    "\n",
    "O melhor modelo será salvo para uso futuro e implementação em produção."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
