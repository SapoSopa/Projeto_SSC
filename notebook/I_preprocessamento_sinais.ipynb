{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d699f17c",
   "metadata": {},
   "source": [
    "# Projeto de Sinais e Sistemas para Computação (SSC)\n",
    "## I - Pré-processamento de Sinais Digitais\n",
    "\n",
    "Este notebook implementa técnicas fundamentais de pré-processamento de sinais digitais, incluindo:\n",
    "- Carregamento e visualização de dados\n",
    "- Aplicação de filtros digitais\n",
    "- Normalização e condicionamento de sinais\n",
    "- Análise no domínio do tempo e frequência\n",
    "\n",
    "### Objetivos\n",
    "- Preparar os dados para extração de características\n",
    "- Aplicar técnicas de filtragem adequadas\n",
    "- Implementar métodos de normalização\n",
    "- Visualizar os resultados do pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22163c0a",
   "metadata": {},
   "source": [
    "## 1. Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313b346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas principais\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, fftfreq\n",
    "import wfdb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import time as time_module\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importar nosso módulo de pré-processamento\n",
    "sys.path.append('../src')\n",
    "from preprocessing import (\n",
    "    load_signal_data, \n",
    "    aplicar_filtro, \n",
    "    normalizar_sinal,\n",
    "    remover_baseline_drift,\n",
    "    detectar_outliers,\n",
    "    verificar_qualidade_sinal,\n",
    "    pipeline_preprocessamento,\n",
    "    salvar_dados_processados\n",
    ")\n",
    "\n",
    "# Configurações de visualização\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14d0f91",
   "metadata": {},
   "source": [
    "## 2. Carregamento e Visualização dos Dados\n",
    "\n",
    "Nesta seção, carregamos os dados de sinais e realizamos uma análise exploratória inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4588d2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARREGAMENTO E ANÁLISE DOS DADOS PTB-XL\n",
      "============================================================\n",
      "1. Carregando metadados do dataset PTB-XL...\n",
      "    Erro ao carregar metadados: [Errno 2] No such file or directory: '../data/raw/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/ptbxl_database.csv'\n",
      "    Processando apenas exemplo individual...\n",
      "\n",
      "2. ANÁLISE DETALHADA - PACIENTE EXEMPLO (00001)\n",
      "============================================================\n",
      "            Erro ao carregar dados: Erro ao carregar arquivo ../data/raw/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/records100/00000/00001_lr: [Errno 2] No such file or directory: '/home/saposopa/Saparia/Projeto_SSC/data/raw/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/records100/00000/00001_lr.hea'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Erro ao carregar arquivo ../data/raw/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/records100/00000/00001_lr: [Errno 2] No such file or directory: '/home/saposopa/Saparia/Projeto_SSC/data/raw/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/records100/00000/00001_lr.hea'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Saparia/Projeto_SSC/notebook/../src/preprocessing/__init__.py:14\u001b[39m, in \u001b[36mload_signal_data\u001b[39m\u001b[34m(filepath)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     record = \u001b[43mwfdb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrdrecord\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m                \u001b[38;5;66;03m# Carrega registro WFDB;\u001b[39;00m\n\u001b[32m     15\u001b[39m     metadata = {\n\u001b[32m     16\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mfs\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(record.fs),                       \u001b[38;5;66;03m# Frequência de amostragem;\u001b[39;00m\n\u001b[32m     17\u001b[39m         \u001b[33m'\u001b[39m\u001b[33msig_name\u001b[39m\u001b[33m'\u001b[39m: record.sig_name,                \u001b[38;5;66;03m# Nomes das derivações;\u001b[39;00m\n\u001b[32m     18\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mn_samples\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(record.p_signal)),     \u001b[38;5;66;03m# Número de amostras;\u001b[39;00m\n\u001b[32m     19\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mn_channels\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(record.sig_name))     \u001b[38;5;66;03m# Número de canais;\u001b[39;00m\n\u001b[32m     20\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Saparia/Projeto_SSC/SSproject/lib/python3.12/site-packages/wfdb/io/record.py:2051\u001b[39m, in \u001b[36mrdrecord\u001b[39m\u001b[34m(record_name, sampfrom, sampto, channels, physical, pn_dir, m2s, smooth_frames, ignore_skew, return_res, force_channels, channel_names, warn_empty)\u001b[39m\n\u001b[32m   2047\u001b[39m         pn_dir = posixpath.join(\n\u001b[32m   2048\u001b[39m             dir_list[\u001b[32m0\u001b[39m], download.get_version(dir_list[\u001b[32m0\u001b[39m]), *dir_list[\u001b[32m1\u001b[39m:]\n\u001b[32m   2049\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m2051\u001b[39m record = \u001b[43mrdheader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpn_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpn_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrd_segments\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2053\u001b[39m \u001b[38;5;66;03m# Set defaults for sampto and channels input variables\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Saparia/Projeto_SSC/SSproject/lib/python3.12/site-packages/wfdb/io/record.py:1855\u001b[39m, in \u001b[36mrdheader\u001b[39m\u001b[34m(record_name, pn_dir, rd_segments)\u001b[39m\n\u001b[32m   1854\u001b[39m dir_name = os.path.abspath(dir_name)\n\u001b[32m-> \u001b[39m\u001b[32m1855\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfsspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1856\u001b[39m \u001b[43m    \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1857\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mascii\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1859\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mignore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1860\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1861\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheader_content\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Saparia/Projeto_SSC/SSproject/lib/python3.12/site-packages/fsspec/core.py:105\u001b[39m, in \u001b[36mOpenFile.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     f = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Saparia/Projeto_SSC/SSproject/lib/python3.12/site-packages/fsspec/spec.py:1338\u001b[39m, in \u001b[36mAbstractFileSystem.open\u001b[39m\u001b[34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[39m\n\u001b[32m   1337\u001b[39m ac = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mautocommit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._intrans)\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m f = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Saparia/Projeto_SSC/SSproject/lib/python3.12/site-packages/fsspec/implementations/local.py:210\u001b[39m, in \u001b[36mLocalFileSystem._open\u001b[39m\u001b[34m(self, path, mode, block_size, **kwargs)\u001b[39m\n\u001b[32m    209\u001b[39m     \u001b[38;5;28mself\u001b[39m.makedirs(\u001b[38;5;28mself\u001b[39m._parent(path), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalFileOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Saparia/Projeto_SSC/SSproject/lib/python3.12/site-packages/fsspec/implementations/local.py:387\u001b[39m, in \u001b[36mLocalFileOpener.__init__\u001b[39m\u001b[34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;28mself\u001b[39m.blocksize = io.DEFAULT_BUFFER_SIZE\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Saparia/Projeto_SSC/SSproject/lib/python3.12/site-packages/fsspec/implementations/local.py:392\u001b[39m, in \u001b[36mLocalFileOpener._open\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.autocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode:\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m     \u001b[38;5;28mself\u001b[39m.f = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compression:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/saposopa/Saparia/Projeto_SSC/data/raw/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/records100/00000/00001_lr.hea'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     sinal_original, metadata = \u001b[43mload_signal_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path_exemplo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    Dados carregados com sucesso!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    Shape do sinal: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msinal_original.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Saparia/Projeto_SSC/notebook/../src/preprocessing/__init__.py:23\u001b[39m, in \u001b[36mload_signal_data\u001b[39m\u001b[34m(filepath)\u001b[39m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m record.p_signal.astype(np.float64), metadata\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mErro ao carregar arquivo \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Erro ao carregar arquivo ../data/raw/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/records100/00000/00001_lr: [Errno 2] No such file or directory: '/home/saposopa/Saparia/Projeto_SSC/data/raw/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/records100/00000/00001_lr.hea'"
     ]
    }
   ],
   "source": [
    "# Definir caminho para os dados\n",
    "dados_base = \"../data/raw/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/\"\n",
    "file_path_exemplo = dados_base + \"records100/00000/00001_lr\"\n",
    "\n",
    "print(\"CARREGAMENTO E ANÁLISE DOS DADOS PTB-XL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Primeiro: carregar metadados do dataset completo\n",
    "print(\"1. Carregando metadados do dataset PTB-XL...\")\n",
    "try:\n",
    "    metadata_ptbxl_path = dados_base + \"ptbxl_database.csv\"\n",
    "    ptbxl_metadata = pd.read_csv(metadata_ptbxl_path)\n",
    "    print(f\"    Dataset carregado: {len(ptbxl_metadata)} registros total\")\n",
    "    \n",
    "    # Filtrar registros disponíveis (100Hz)\n",
    "    registros_disponíveis = ptbxl_metadata[ptbxl_metadata['filename_lr'].notna()].copy()\n",
    "    print(f\"    Registros com 100Hz disponíveis: {len(registros_disponíveis)}\")\n",
    "\n",
    "    # Mostrar estatísticas do dataset\n",
    "    print(f\"\\n  ESTATÍSTICAS DO DATASET:\")\n",
    "    print(f\"   Idade média: {registros_disponíveis['age'].mean():.1f} ± {registros_disponíveis['age'].std():.1f} anos\")\n",
    "    print(f\"   Distribuição por sexo:\")\n",
    "    sex_counts = registros_disponíveis['sex'].value_counts()\n",
    "    for sex, count in sex_counts.items():\n",
    "        if sex == 0:\n",
    "            print(f\"     Mulher: {count} ({100*count/len(registros_disponíveis):.1f}%)\")\n",
    "        else:\n",
    "            print(f\"     Homem: {count} ({100*count/len(registros_disponíveis):.1f}%)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"    Erro ao carregar metadados: {e}\")\n",
    "    print(\"    Processando apenas exemplo individual...\")\n",
    "    # Fallback: criar DataFrame mínimo para continuar\n",
    "    registros_disponíveis = pd.DataFrame({\n",
    "        'ecg_id': [1],\n",
    "        'patient_id': [1], \n",
    "        'filename_lr': ['records100/00000/00001_lr'],\n",
    "        'age': [50],\n",
    "        'sex': [0]\n",
    "    })\n",
    "\n",
    "# Segundo: exemplo detalhado com um paciente\n",
    "print(f\"\\n2. ANÁLISE DETALHADA - PACIENTE EXEMPLO (00001)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    sinal_original, metadata = load_signal_data(file_path_exemplo)\n",
    "    print(f\"    Dados carregados com sucesso!\")\n",
    "    print(f\"    Shape do sinal: {sinal_original.shape}\")\n",
    "    print(f\"    Frequência de amostragem: {metadata['fs']} Hz\")\n",
    "    print(f\"    Número de canais: {metadata['n_channels']}\")\n",
    "    print(f\"    Derivações: {metadata['sig_name']}\")\n",
    "    print(f\"    Duração: {metadata['n_samples']/metadata['fs']:.1f} segundos\")\n",
    "except Exception as e:\n",
    "    print(f\"            Erro ao carregar dados: {e}\")\n",
    "    raise\n",
    "\n",
    "# Visualização detalhada do exemplo\n",
    "fig, axes = plt.subplots(4, 3, figsize=(18, 12))\n",
    "fig.suptitle('Visualização Detalhada - ECG de 12 Derivações (Paciente 00001)', fontsize=16, fontweight='bold')\n",
    "\n",
    "time_axis = np.arange(len(sinal_original)) / metadata['fs']\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < metadata['n_channels']:\n",
    "        ax.plot(time_axis, sinal_original[:, i], 'b-', linewidth=0.8)\n",
    "        ax.set_title(f\"{metadata['sig_name'][i]}\", fontweight='bold')\n",
    "        ax.set_xlabel('Tempo (s)')\n",
    "        ax.set_ylabel('Amplitude (mV)')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Estatísticas básicas\n",
    "        rms = np.sqrt(np.mean(sinal_original[:, i]**2))\n",
    "        ax.text(0.02, 0.95, f'RMS: {rms:.3f}', transform=ax.transAxes, \n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Verificar qualidade do exemplo\n",
    "print(\"\\n   ANÁLISE DE QUALIDADE DO EXEMPLO\")\n",
    "print(\"=\"*50)\n",
    "qualidade_original = verificar_qualidade_sinal(sinal_original, metadata['fs'])\n",
    "\n",
    "for canal, metricas in qualidade_original.items():\n",
    "    derivacao = metadata['sig_name'][int(canal.split('_')[1])]\n",
    "    print(f\"    {derivacao}:\")\n",
    "    print(f\"    SNR: {metricas['snr_estimado']:.1f} dB\")\n",
    "    print(f\"    Amplitude máxima: {metricas['amplitude_maxima']:.3f} mV\")\n",
    "    print(f\"    Saturação: {metricas['saturacao']*100:.2f}%\")\n",
    "    print(f\"    RMS: {metricas['rms']:.3f}\")\n",
    "\n",
    "print(f\"Dados disponíveis para processamento: {len(registros_disponíveis)} registros\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57c78f8",
   "metadata": {},
   "source": [
    "## 2.1 Filtragem Digital\n",
    "\n",
    "Aplicação de diferentes tipos de filtros para remover ruído e componentes indesejados do sinal se necessário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf20d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n                FILTRAGEM DIGITAL - EXEMPLO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Aplicar diferentes tipos de filtros\n",
    "fs = metadata['fs']\n",
    "\n",
    "# 1. Remover deriva da linha de base\n",
    "print(\" Removendo deriva da linha de base...\")\n",
    "sinal_sem_deriva = remover_baseline_drift(sinal_original, fs, freq_corte=0.5)\n",
    "\n",
    "# 2. Aplicar filtro passa-banda padrão para ECG\n",
    "print(\" Aplicando filtro passa-banda (0.5-45 Hz)...\")\n",
    "sinal_filtrado = aplicar_filtro(sinal_sem_deriva, fs, tipo='bandpass', \n",
    "                               frequencias=(0.5, 45.0), ordem=4)\n",
    "\n",
    "# 3. Detectar outliers\n",
    "print(\" Detectando outliers...\")\n",
    "outliers = detectar_outliers(sinal_filtrado, threshold=3.0)\n",
    "num_outliers = np.sum(outliers)\n",
    "print(f\"    Outliers detectados: {num_outliers} de {sinal_filtrado.size} pontos ({100*num_outliers/sinal_filtrado.size:.3f}%)\")\n",
    "\n",
    "# Visualização comparativa - Antes e Depois da Filtragem\n",
    "derivacao_exemplo = 1  # Lead II para exemplo\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('Comparação: Antes e Depois da Filtragem (Lead II)', fontsize=16, fontweight='bold')\n",
    "\n",
    "time_axis_filtro = np.arange(len(sinal_original)) / fs\n",
    "\n",
    "# Sinal original\n",
    "axes[0,0].plot(time_axis_filtro, sinal_original[:, derivacao_exemplo], 'b-', linewidth=0.8)\n",
    "axes[0,0].set_title('Sinal Original')\n",
    "axes[0,0].set_xlabel('Tempo (s)')\n",
    "axes[0,0].set_ylabel('Amplitude (mV)')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Sinal filtrado\n",
    "axes[0,1].plot(time_axis_filtro, sinal_filtrado[:, derivacao_exemplo], 'g-', linewidth=0.8)\n",
    "axes[0,1].set_title('Sinal Filtrado')\n",
    "axes[0,1].set_xlabel('Tempo (s)')\n",
    "axes[0,1].set_ylabel('Amplitude (mV)')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Análise espectral - Original\n",
    "freqs_orig = fftfreq(len(sinal_original), 1/fs)\n",
    "fft_orig = np.abs(fft(sinal_original[:, derivacao_exemplo]))\n",
    "mask_orig = freqs_orig > 0\n",
    "axes[1,0].semilogy(freqs_orig[mask_orig], fft_orig[mask_orig], 'b-', linewidth=0.8)\n",
    "axes[1,0].set_title('Espectro - Original')\n",
    "axes[1,0].set_xlabel('Frequência (Hz)')\n",
    "axes[1,0].set_ylabel('Amplitude')\n",
    "axes[1,0].set_xlim(0, 100)\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Análise espectral - Filtrado\n",
    "fft_filt = np.abs(fft(sinal_filtrado[:, derivacao_exemplo]))\n",
    "axes[1,1].semilogy(freqs_orig[mask_orig], fft_filt[mask_orig], 'g-', linewidth=0.8)\n",
    "axes[1,1].set_title('Espectro - Filtrado')\n",
    "axes[1,1].set_xlabel('Frequência (Hz)')\n",
    "axes[1,1].set_ylabel('Amplitude')\n",
    "axes[1,1].set_xlim(0, 100)\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comparar qualidade antes e depois\n",
    "print(\"\\n   COMPARAÇÃO DE QUALIDADE: ANTES vs DEPOIS DA FILTRAGEM\")\n",
    "print(\"=\"*60)\n",
    "qualidade_filtrado = verificar_qualidade_sinal(sinal_filtrado, fs)\n",
    "\n",
    "print(f\"    {'Derivação':<8} {' SNR Original':<12} {'   SNR Filtrado':<12} {'   Melhoria':<10}\")\n",
    "print(\"    \" + \"-\" * 50)\n",
    "for i in range(metadata['n_channels']):\n",
    "    derivacao = metadata['sig_name'][i]\n",
    "    snr_orig = qualidade_original[f'canal_{i}']['snr_estimado']\n",
    "    snr_filt = qualidade_filtrado[f'canal_{i}']['snr_estimado']\n",
    "    melhoria = snr_filt - snr_orig\n",
    "    print(f\"    {derivacao:<8}      {snr_orig:<12.1f}    {snr_filt:<12.1f} {melhoria:+.1f} dB\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c074b16d",
   "metadata": {},
   "source": [
    "## 2.2 Normalização e Condicionamento do Sinal\n",
    "\n",
    "Aplicação de técnicas de normalização para padronizar os sinais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9acf353",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n            NORMALIZAÇÃO E CONDICIONAMENTO DO SINAL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Aplicar diferentes métodos de normalização\n",
    "print(\" Aplicando normalização Z-score, Min-Max e Robust...\")\n",
    "sinal_zscore = normalizar_sinal(sinal_filtrado, metodo='zscore')\n",
    "\n",
    "sinal_minmax = normalizar_sinal(sinal_filtrado, metodo='minmax')\n",
    "\n",
    "sinal_robust = normalizar_sinal(sinal_filtrado, metodo='robust')\n",
    "\n",
    "# Visualização comparativa dos métodos de normalização\n",
    "derivacao_exemplo = 1  # Lead II\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle(f'Comparação de Métodos de Normalização (Lead {metadata[\"sig_name\"][derivacao_exemplo]})', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "time_axis_norm = np.arange(len(sinal_filtrado)) / fs\n",
    "\n",
    "# Sinal filtrado (antes da normalização)\n",
    "axes[0,0].plot(time_axis_norm, sinal_filtrado[:, derivacao_exemplo], 'b-', linewidth=0.8)\n",
    "axes[0,0].set_title('Sinal Filtrado (Original)')\n",
    "axes[0,0].set_xlabel('Tempo (s)')\n",
    "axes[0,0].set_ylabel('Amplitude (mV)')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Z-score\n",
    "axes[0,1].plot(time_axis_norm, sinal_zscore[:, derivacao_exemplo], 'r-', linewidth=0.8)\n",
    "axes[0,1].set_title('Normalização Z-score')\n",
    "axes[0,1].set_xlabel('Tempo (s)')\n",
    "axes[0,1].set_ylabel('Amplitude (padronizada)')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Min-Max\n",
    "axes[1,0].plot(time_axis_norm, sinal_minmax[:, derivacao_exemplo], 'g-', linewidth=0.8)\n",
    "axes[1,0].set_title('Normalização Min-Max')\n",
    "axes[1,0].set_xlabel('Tempo (s)')\n",
    "axes[1,0].set_ylabel('Amplitude (0-1)')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Robust\n",
    "axes[1,1].plot(time_axis_norm, sinal_robust[:, derivacao_exemplo], 'm-', linewidth=0.8)\n",
    "axes[1,1].set_title('Normalização Robust')\n",
    "axes[1,1].set_xlabel('Tempo (s)')\n",
    "axes[1,1].set_ylabel('Amplitude (robust)')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Análise estatística dos métodos de normalização\n",
    "print(\"\\n     ANÁLISE ESTATÍSTICA DOS MÉTODOS DE NORMALIZAÇÃO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "metodos = {\n",
    "    'Original': sinal_filtrado,\n",
    "    'Z-score': sinal_zscore,\n",
    "    'Min-Max': sinal_minmax,\n",
    "    'Robust': sinal_robust\n",
    "}\n",
    "\n",
    "print(f\"{'Método':<12} {'Média':<10} {'Std':<10} {'Min':<10} {'Max':<10}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for nome, sinal in metodos.items():\n",
    "    dados_canal = sinal[:, derivacao_exemplo]\n",
    "    media = np.mean(dados_canal)\n",
    "    std = np.std(dados_canal)\n",
    "    minimo = np.min(dados_canal)\n",
    "    maximo = np.max(dados_canal)\n",
    "    print(f\"{nome:<12} {media:<10.3f} {std:<10.3f} {minimo:<10.3f} {maximo:<10.3f}\")\n",
    "\n",
    "# Histogramas comparativos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle(f' Distribuição dos Valores - Lead {metadata[\"sig_name\"][derivacao_exemplo]}', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "axes[0,0].hist(sinal_filtrado[:, derivacao_exemplo], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0,0].set_title('Original')\n",
    "axes[0,0].set_ylabel('Frequência')\n",
    "\n",
    "axes[0,1].hist(sinal_zscore[:, derivacao_exemplo], bins=50, alpha=0.7, color='red', edgecolor='black')\n",
    "axes[0,1].set_title('Z-score')\n",
    "\n",
    "axes[1,0].hist(sinal_minmax[:, derivacao_exemplo], bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[1,0].set_title('Min-Max')\n",
    "axes[1,0].set_ylabel('Frequência')\n",
    "axes[1,0].set_xlabel('Amplitude')\n",
    "\n",
    "axes[1,1].hist(sinal_robust[:, derivacao_exemplo], bins=50, alpha=0.7, color='magenta', edgecolor='black')\n",
    "axes[1,1].set_title('Robust')\n",
    "axes[1,1].set_xlabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4115a3da",
   "metadata": {},
   "source": [
    "## 3. Pipeline Completo e Comparação Final\n",
    "\n",
    "Nesta seção final, aplicamos o pipeline automatizado que integra todas as etapas de pré-processamento desenvolvidas anteriormente. O pipeline garante:\n",
    "\n",
    "- **Reprodutibilidade**: Mesma sequência de processamento para todos os sinais\n",
    "- **Consistência**: Parâmetros otimizados aplicados uniformemente  \n",
    "- **Eficiência**: Processamento automatizado sem intervenção manual\n",
    "- **Qualidade**: Verificação automática dos resultados\n",
    "\n",
    "O pipeline aplica na ordem otimizada:\n",
    "1. Carregamento dos dados WFDB\n",
    "2. Remoção de deriva da linha de base\n",
    "3. Filtragem passa-banda (0.5-45 Hz)\n",
    "4. Normalização Z-score\n",
    "5. Verificação de qualidade final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afff09ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n           PIPELINE COMPLETO DE PRÉ-PROCESSAMENTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Demonstração com um exemplo\n",
    "print(\"     Executando pipeline automatizado (exemplo)\")\n",
    "sinal_processado, metadata_final = pipeline_preprocessamento(\n",
    "    file_path_exemplo,\n",
    "    aplicar_filtro_flag=True,\n",
    "    normalizar_flag=True,\n",
    "    remover_deriva=True\n",
    ")\n",
    "\n",
    "# Comparação final: Original vs Processado (exemplo)\n",
    "fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
    "fig.suptitle('  COMPARAÇÃO FINAL: Original vs Processado (Todas as Derivações)', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "time_axis_pipeline = np.arange(len(sinal_original)) / fs\n",
    "\n",
    "for i in range(metadata['n_channels']):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    \n",
    "    # Sinal original\n",
    "    axes[row, col].plot(time_axis_pipeline, sinal_original[:, i], 'b-', linewidth=0.8, alpha=0.7, label='Original')\n",
    "    # Sinal processado\n",
    "    axes[row, col].plot(time_axis_pipeline, sinal_processado[:, i], 'r-', linewidth=0.8, label='Processado')\n",
    "    \n",
    "    axes[row, col].set_title(f\"{metadata['sig_name'][i]}\", fontweight='bold')\n",
    "    axes[row, col].set_xlabel('Tempo (s)')\n",
    "    axes[row, col].set_ylabel('Amplitude')\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "    axes[row, col].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Relatório final de qualidade do exemplo\n",
    "print(\"\\n               RELATÓRIO FINAL DE QUALIDADE (EXEMPLO)\")\n",
    "print(\"=\"*70)\n",
    "qualidade_final = metadata_final['qualidade']\n",
    "\n",
    "print(f\" {'Derivação':<8}    {'SNR (dB)':<10}    {'Amplitude Max':<15}   {'Saturação (%)':<15}   {'Status':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i in range(metadata['n_channels']):\n",
    "    derivacao = metadata['sig_name'][i]\n",
    "    canal_key = f'canal_{i}'\n",
    "    snr = qualidade_final[canal_key]['snr_estimado']\n",
    "    amp_max = qualidade_final[canal_key]['amplitude_maxima']\n",
    "    saturacao = qualidade_final[canal_key]['saturacao'] * 100\n",
    "    \n",
    "    # Determinar status\n",
    "    if snr >= 20 and saturacao < 1:\n",
    "        status = \"Ótimo\"\n",
    "    elif snr >= 15 and saturacao < 2:\n",
    "        status = \"Bom\"\n",
    "    else:\n",
    "        status = \"Atenção\"\n",
    "    \n",
    "    print(f\"  {derivacao:<8}    {snr:<10.1f}       {amp_max:<15.3f}  {saturacao:<15.2f}{status:<10}\")\n",
    "\n",
    "# Salvar dados do exemplo\n",
    "print(f\"\\n  SALVANDO DADOS DO EXEMPLO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "arquivos_salvos = salvar_dados_processados(\n",
    "    sinal_processado, \n",
    "    metadata_final, \n",
    "    ecg_id=1,\n",
    "    output_dir=\"../data/processed\"\n",
    ")\n",
    "\n",
    "print(f\"    Arquivos gerados:\")\n",
    "for i, arquivo in enumerate(arquivos_salvos, 1):\n",
    "    nome_arquivo = arquivo.split('/')[-1]\n",
    "    print(f\"   {i}. {nome_arquivo}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e2897a",
   "metadata": {},
   "source": [
    "## 3.1 Pipeline Completo em Pacote\n",
    "Vamos efetivamente preprocessar todos os dados para utilizá-los depois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e761d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESSAMENTO EM LOTE DE TODOS OS REGISTROS\n",
    "print(f\"    PROCESSAMENTO EM LOTE - TODOS OS REGISTROS PTB-XL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Decidir quantos registros processar\n",
    "registros_para_processar = registros_disponíveis  # REMOVA .head(100) para processar TODOS\n",
    "print(f\"    Processando {len(registros_para_processar)} registros\")\n",
    "\n",
    "# Dicionário para armazenar resultados do lote\n",
    "resultados_lote = {\n",
    "    'ecg_id': [],\n",
    "    'patient_id': [],\n",
    "    'age': [],\n",
    "    'sex': [],\n",
    "    'status': [],\n",
    "    'snr_medio_original': [],\n",
    "    'snr_medio_final': [],\n",
    "    'melhoria_snr': [],\n",
    "    'outliers_percent': [],\n",
    "    'canais_com_boa_qualidade': [],\n",
    "    'tempo_processamento': [],\n",
    "    'pasta_destino': [],\n",
    "    'arquivo_sinal': [],\n",
    "    'arquivo_metadata': []\n",
    "}\n",
    "\n",
    "# Contadores para estatísticas\n",
    "total_registros = len(registros_para_processar)\n",
    "sucessos = 0\n",
    "erros = 0\n",
    "start_time_total = time_module.time()\n",
    "\n",
    "# CONTADOR DE PASTAS CRIADAS\n",
    "pastas_criadas = set()\n",
    "\n",
    "# Loop através de todos os registros\n",
    "for idx, (_, row) in enumerate(registros_para_processar.iterrows()):\n",
    "    ecg_id = None\n",
    "    patient_id = None  \n",
    "    age = 0\n",
    "    sex = 2  # Valor padrão para sexo desconhecido\n",
    "    \n",
    "    try:\n",
    "        # Progresso a cada 100 registros\n",
    "        if idx % 100 == 0 or idx == total_registros - 1:\n",
    "            progresso = (idx + 1) / total_registros * 100\n",
    "            tempo_decorrido = time_module.time() - start_time_total\n",
    "            if idx > 0:\n",
    "                tempo_estimado = (tempo_decorrido / (idx + 1)) * total_registros\n",
    "                print(f\"\\n  Progresso: {idx+1}/{total_registros} ({progresso:.1f}%) - \"\n",
    "                      f\"Sucessos: {sucessos}, Erros: {erros}\")\n",
    "                print(f\"    Tempo decorrido: {tempo_decorrido/60:.1f}min - \"\n",
    "                      f\"Estimativa total: {tempo_estimado/60:.1f}min\")\n",
    "        \n",
    "        # Extrair informações do registro\n",
    "        ecg_id = row['ecg_id']\n",
    "        patient_id = row['patient_id']\n",
    "        age = row['age'] if pd.notna(row['age']) else 0\n",
    "        sex = row['sex'] if pd.notna(row['sex']) else 'unknown'\n",
    "        filename = row['filename_lr']\n",
    "\n",
    "        # Verificar se o filename está disponível\n",
    "        if pd.isna(filename):\n",
    "            raise ValueError(\"Filename não disponível\")\n",
    "        \n",
    "        # Construir caminho completo\n",
    "        file_path_completo = dados_base + filename\n",
    "        \n",
    "        # Medir tempo de processamento individual\n",
    "        inicio_individual = time_module.time()\n",
    "        \n",
    "        # Aplicar pipeline de pré-processamento\n",
    "        sinal_processado_lote, metadata_proc = pipeline_preprocessamento(\n",
    "            file_path_completo,\n",
    "            aplicar_filtro_flag=True,\n",
    "            normalizar_flag=True,\n",
    "            remover_deriva=True\n",
    "        )\n",
    "        \n",
    "        # Carregar sinal original para comparação\n",
    "        sinal_original_lote, metadata_original = load_signal_data(file_path_completo)\n",
    "        qualidade_original_lote = verificar_qualidade_sinal(sinal_original_lote, metadata_original['fs'])\n",
    "        \n",
    "        # Calcular métricas\n",
    "        qualidade_final_lote = metadata_proc['qualidade']\n",
    "        \n",
    "        snr_orig = np.mean([qualidade_original_lote[f'canal_{j}']['snr_estimado'] \n",
    "                           for j in range(metadata_proc['n_channels'])])\n",
    "        snr_final = np.mean([qualidade_final_lote[f'canal_{j}']['snr_estimado'] \n",
    "                            for j in range(metadata_proc['n_channels'])])\n",
    "        \n",
    "        # Contar canais com boa qualidade (SNR >= 15 dB)\n",
    "        canais_bons = len([i for i in range(metadata_proc['n_channels']) \n",
    "                          if qualidade_final_lote[f'canal_{i}']['snr_estimado'] >= 15])\n",
    "        \n",
    "        # Calcular outliers\n",
    "        outliers_lote = detectar_outliers(sinal_processado_lote, threshold=3.0)\n",
    "        outliers_pct = (np.sum(outliers_lote) / sinal_processado_lote.size) * 100\n",
    "        \n",
    "        # Salvar dados processados\n",
    "        arquivos = salvar_dados_processados(\n",
    "            sinal_processado_lote, \n",
    "            metadata_proc, \n",
    "            ecg_id=ecg_id,  # ECG ID como identificador\n",
    "            output_dir=\"../data/processed\"\n",
    "        )\n",
    "        \n",
    "        # RASTREAR PASTA CRIADA\n",
    "        folder_number = (ecg_id - 1) // 1000\n",
    "        pasta_criada = f\"records{folder_number:03d}\"\n",
    "        pastas_criadas.add(pasta_criada)\n",
    "\n",
    "        tempo_individual = time_module.time() - inicio_individual\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        resultados_lote['ecg_id'].append(ecg_id)\n",
    "        resultados_lote['patient_id'].append(patient_id)\n",
    "        resultados_lote['age'].append(age)\n",
    "        resultados_lote['sex'].append(sex)\n",
    "        resultados_lote['status'].append('Sucesso')\n",
    "        resultados_lote['snr_medio_original'].append(snr_orig)\n",
    "        resultados_lote['snr_medio_final'].append(snr_final)\n",
    "        resultados_lote['melhoria_snr'].append(snr_final - snr_orig)\n",
    "        resultados_lote['outliers_percent'].append(outliers_pct)\n",
    "        resultados_lote['canais_com_boa_qualidade'].append(canais_bons)\n",
    "        resultados_lote['tempo_processamento'].append(tempo_individual)\n",
    "        resultados_lote['pasta_destino'].append(pasta_criada)\n",
    "        resultados_lote['arquivo_sinal'].append(arquivos[0])\n",
    "        resultados_lote['arquivo_metadata'].append(arquivos[1])\n",
    "        \n",
    "        sucessos += 1\n",
    "        \n",
    "    # Tratamento específico para arquivo não encontrado\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"        Arquivo não encontrado - ECG {ecg_id}: {filename}\")\n",
    "        # Adicionar entrada de erro\n",
    "        resultados_lote['ecg_id'].append(ecg_id if ecg_id is not None else 0)\n",
    "        resultados_lote['patient_id'].append(patient_id if patient_id is not None else 0)\n",
    "        resultados_lote['age'].append(age)\n",
    "        resultados_lote['sex'].append(sex)\n",
    "        resultados_lote['status'].append('Arquivo não encontrado')\n",
    "        # Adicionar zeros para outras métricas\n",
    "        for key in ['snr_medio_original', 'snr_medio_final', 'melhoria_snr', 'outliers_percent', \n",
    "                   'canais_com_boa_qualidade', 'tempo_processamento']:\n",
    "            resultados_lote[key].append(0)\n",
    "        resultados_lote['pasta_destino'].append('N/A')\n",
    "        resultados_lote['arquivo_sinal'].append('N/A')\n",
    "        resultados_lote['arquivo_metadata'].append('N/A')\n",
    "        erros += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Tratamento robusto de erros\n",
    "        print(f\"    Erro no ECG {ecg_id if ecg_id is not None else 'N/A'}: {str(e)[:100]}...\")\n",
    "        \n",
    "        # Adicionar entrada de erro com valores seguros\n",
    "        resultados_lote['ecg_id'].append(ecg_id if ecg_id is not None else 0)\n",
    "        resultados_lote['patient_id'].append(patient_id if patient_id is not None else 0)\n",
    "        resultados_lote['age'].append(age)\n",
    "        resultados_lote['sex'].append(sex)\n",
    "        resultados_lote['status'].append(f'     Erro: {str(e)[:50]}')\n",
    "        # Adicionar zeros para outras métricas\n",
    "        for key in ['snr_medio_original', 'snr_medio_final', 'melhoria_snr', 'outliers_percent', \n",
    "                   'canais_com_boa_qualidade', 'tempo_processamento']:\n",
    "            resultados_lote[key].append(0)\n",
    "        resultados_lote['pasta_destino'].append('N/A')\n",
    "        resultados_lote['arquivo_sinal'].append('N/A')\n",
    "        resultados_lote['arquivo_metadata'].append('N/A')\n",
    "        \n",
    "        erros += 1\n",
    "\n",
    "tempo_total = time_module.time() - start_time_total\n",
    "\n",
    "# Criar DataFrame final com todos os resultados\n",
    "df_resultados_lote = pd.DataFrame(resultados_lote)\n",
    "\n",
    "print(f\"\\n      PROCESSAMENTO EM LOTE CONCLUÍDO!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"    Tempo total: {tempo_total/60:.2f} minutos\")\n",
    "print(f\"    Processamentos bem-sucedidos: {sucessos}/{total_registros} ({100*sucessos/total_registros:.1f}%)\")\n",
    "print(f\"    Processamentos com erro: {erros}/{total_registros} ({100*erros/total_registros:.1f}%)\")\n",
    "print(f\"    Total de pastas criadas: {len(pastas_criadas)}\")\n",
    "print(f\"    Pastas: {sorted(list(pastas_criadas))}\")\n",
    "\n",
    "# Estatísticas dos processamentos bem-sucedidos\n",
    "sucessos_df = df_resultados_lote[df_resultados_lote['status'] == 'Sucesso']\n",
    "\n",
    "if len(sucessos_df) > 0:\n",
    "    print(f\"\\n      ESTATÍSTICAS DOS SUCESSOS:\")\n",
    "    print(f\"        SNR médio original: {sucessos_df['snr_medio_original'].mean():.1f} ± {sucessos_df['snr_medio_original'].std():.1f} dB\")\n",
    "    print(f\"        SNR médio final: {sucessos_df['snr_medio_final'].mean():.1f} ± {sucessos_df['snr_medio_final'].std():.1f} dB\")\n",
    "    print(f\"        Melhoria média: {sucessos_df['melhoria_snr'].mean():.1f} ± {sucessos_df['melhoria_snr'].std():.1f} dB\")\n",
    "    print(f\"        Outliers médios: {sucessos_df['outliers_percent'].mean():.3f}% dos dados\")\n",
    "    print(f\"        Canais com boa qualidade: {sucessos_df['canais_com_boa_qualidade'].mean():.1f}/12 canais\")\n",
    "    print(f\"        Tempo médio por registro: {sucessos_df['tempo_processamento'].mean():.2f}s\")\n",
    "    \n",
    "    # Estatísticas demográficas\n",
    "    print(f\"\\n  DADOS DEMOGRÁFICOS:\")\n",
    "    print(f\"   Idade média: {sucessos_df['age'].mean():.1f} ± {sucessos_df['age'].std():.1f} anos\")\n",
    "    print(f\"   Distribuição por sexo:\")\n",
    "    sex_counts = sucessos_df['sex'].value_counts()\n",
    "    for sex, count in sex_counts.items():\n",
    "        if sex == 0:\n",
    "            print(f\"     Mulher: {count} ({100*count/len(sucessos_df):.1f}%)\")\n",
    "        else:\n",
    "            print(f\"     Homem: {count} ({100*count/len(sucessos_df):.1f}%)\")\n",
    "\n",
    "# Salvar relatórios\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Criar diretório para salvar relatórios\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "# Relatório completo\n",
    "relatorio_completo_path = f\"../data/processed/relatorio_processamento_completo_{timestamp}.csv\"\n",
    "df_resultados_lote.to_csv(relatorio_completo_path, index=False)\n",
    "\n",
    "# Relatório apenas sucessos\n",
    "relatorio_sucessos_path = f\"../data/processed/relatorio_sucessos_{timestamp}.csv\"\n",
    "sucessos_df.to_csv(relatorio_sucessos_path, index=False)\n",
    "\n",
    "# Relatório de erros\n",
    "if erros > 0:\n",
    "    erros_df = df_resultados_lote[df_resultados_lote['status'] != 'Sucesso']\n",
    "    relatorio_erros_path = f\"../data/processed/relatorio_erros_{timestamp}.csv\"\n",
    "    erros_df.to_csv(relatorio_erros_path, index=False)\n",
    "    print(f\"    Relatório de erros salvo: {relatorio_erros_path}\")\n",
    "\n",
    "print(f\"\\n  RELATÓRIOS SALVOS:\")\n",
    "print(f\"    Relatório completo: {relatorio_completo_path}\")\n",
    "print(f\"    Relatório sucessos: {relatorio_sucessos_path}\")\n",
    "\n",
    "print(f\"\\n  DADOS PRONTOS PARA O PRÓXIMO NOTEBOOK\")\n",
    "print(f\"    Total de arquivos processados em ../data/processed/: {sucessos} arquivos\")\n",
    "\n",
    "# Mostrar amostra dos resultados\n",
    "if len(sucessos_df) > 0:\n",
    "    print(f\"\\n              AMOSTRA DOS RESULTADOS (primeiros 10 sucessos):\")\n",
    "    print(sucessos_df[['ecg_id', 'patient_id', 'age', 'snr_medio_final', 'canais_com_boa_qualidade']].head(10).to_string(index=False))\n",
    "else:\n",
    "    print(f\"\\n              Nenhum registro processado com sucesso.\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7687d8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 4. Resumo e Conclusões\n",
    "\n",
    "### Técnicas Implementadas:\n",
    " **Carregamento de dados WFDB (PTB-XL)** - Importação dos sinais ECG do dataset  \n",
    " **Remoção de deriva da linha de base** - Filtro passa-alta 0.5 Hz  \n",
    " **Filtragem passa-banda** - Remoção de ruídos (0.5-45 Hz)  \n",
    " **Detecção de outliers** - Identificação de artefatos usando z-score  \n",
    " **Normalização Z-score** - Padronização para algoritmos ML  \n",
    " **Verificação de qualidade** - Métricas automáticas de SNR e saturação  \n",
    " **Pipeline automatizado** - Processamento reprodutível e consistente  \n",
    "\n",
    "### Resultados Obtidos:\n",
    "- Melhoria significativa na qualidade do sinal (SNR)\n",
    "- Remoção eficaz de ruídos e artefatos\n",
    "- Sinais padronizados prontos para extração de características\n",
    "- Dados salvos em formato adequado para os próximos notebooks\n",
    "\n",
    "---\n",
    "** Dados pré-processados salvos em [`../data/processed/`](../data/processed/)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
